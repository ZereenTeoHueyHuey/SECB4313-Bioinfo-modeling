{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZereenTeoHueyHuey/SECB4313-Bioinfo-modeling/blob/main/W3_Heart_Disease_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1q_qKIV2t2u"
      },
      "source": [
        "#Import all library needed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,BatchNormalization, Dropout\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "#confusion matrix visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 1. Link notebook with google drive and access data from your personal Gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "### 2.Set the data path for dataset and model location (ex: model_loc = \"/content/gdrive/My Drive/Dataset/\")\n",
        "dataset_dir = '/content/gdrive/My Drive/dataset/'\n",
        "model_loc = '/content/gdrive/My Drive/dataset/'\n",
        "\n",
        "print(os.listdir(dataset_dir))\n",
        "data = pd.read_csv(dataset_dir+'heart.csv')"
      ],
      "metadata": {
        "id": "WazdlOZefP88",
        "outputId": "14e71410-291e-4384-b502-11a8ba964407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "['heart.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZADep6q2t3D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "b7f43ed3-a4e5-45ac-dab2-78b60c973056"
      },
      "source": [
        "### 3. Insert Exploratory data analysis (EDA) steps to analyze and investigate datasets.\n",
        "print(data.shape)\n",
        "data.info()\n",
        "data.head()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(303, 14)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd92c9f1-f34a-405b-830f-dc7417228945\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd92c9f1-f34a-405b-830f-dc7417228945')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd92c9f1-f34a-405b-830f-dc7417228945 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd92c9f1-f34a-405b-830f-dc7417228945');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f7583499-eb4b-4919-8dc1-043ddca4fe6f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7583499-eb4b-4919-8dc1-043ddca4fe6f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f7583499-eb4b-4919-8dc1-043ddca4fe6f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 303,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 29,\n        \"max\": 77,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          46,\n          66,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 94,\n        \"max\": 200,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          104,\n          123\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 126,\n        \"max\": 564,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          277,\n          169\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 71,\n        \"max\": 202,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          159,\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1610750220686348,\n        \"min\": 0.0,\n        \"max\": 6.2,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          1.9,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ylkru32t27"
      },
      "source": [
        "### 4. What is the purpose of the code that sets a list of categorical variables\n",
        "### in a dataset and then casts those variables to the object data type using the astype() function?\n",
        "### - To convert the datatype to object since the columns can acts as category variable for easier manipulation\n",
        "catagorialList = ['sex','cp','fbs','restecg','exang','ca','thal']\n",
        "for item in catagorialList:\n",
        "    data[item] = data[item].astype('object') #casting to object"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNbqP4z32t3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ca8aa1-d43c-4337-a7ba-b34fab91a3ad"
      },
      "source": [
        " ### 5. Create more data by categorical variable into indicator variables using 'get_dummies' function\n",
        "data = pd.get_dummies(data,drop_first=True)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-78-a28a0805ee1f>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data,drop_first=True)\n",
            "<ipython-input-78-a28a0805ee1f>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data,drop_first=True)\n",
            "<ipython-input-78-a28a0805ee1f>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data,drop_first=True)\n",
            "<ipython-input-78-a28a0805ee1f>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data,drop_first=True)\n",
            "<ipython-input-78-a28a0805ee1f>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data,drop_first=True)\n",
            "<ipython-input-78-a28a0805ee1f>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data,drop_first=True)\n",
            "<ipython-input-78-a28a0805ee1f>:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data,drop_first=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhlOEgqg2t3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c10694-8ab5-45c0-a844-a2a806c80bd4"
      },
      "source": [
        "### 6. Explain line 3,4 and 5 and print the shape of x and y\n",
        "\n",
        "y = data['target'].values\n",
        "## to return the numpy representation for 'target' column\n",
        "y = y.reshape(y.shape[0],1)\n",
        "## to give new shape to an array without changing its data\n",
        "x = data.drop(['target'],axis=1)\n",
        "##drop the column for 'target'\n",
        "print(y.shape)\n",
        "print(x.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(303, 1)\n",
            "(303, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEGdOBJu2t3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e262cc78-4429-4dfd-bb8b-710d256a33d8"
      },
      "source": [
        "### 7. Create a simple dataset and demonstrate the normalization code on the simple dataset\n",
        "data = pd.DataFrame({ \"A\": [10,20,30], \"B\": [50, 40, 30], \"C\": [100,200,300]})\n",
        "min_val = np.min(data)\n",
        "max_val = np.max(data)\n",
        "normalized_data = (data - min_val) / (max_val - min_val)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 8. Describe the heart dataset after implementing the min max normalization\n",
        "#Normalize data (range 0 - 1)\n",
        "minx = np.min(x)\n",
        "maxx = np.max(x)\n",
        "x = (x - minx) / (maxx - minx)\n",
        "x.head()"
      ],
      "metadata": {
        "id": "asoFBQaumuKA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "399feac3-76a9-4bec-c875-dc29df177ae9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  trestbps      chol   thalach   oldpeak  slope  sex_1  cp_1  cp_2  \\\n",
              "0  0.708333  0.481132  0.244292  0.603053  0.370968    0.0    1.0   0.0   0.0   \n",
              "1  0.166667  0.339623  0.283105  0.885496  0.564516    0.0    1.0   0.0   1.0   \n",
              "2  0.250000  0.339623  0.178082  0.770992  0.225806    1.0    0.0   1.0   0.0   \n",
              "3  0.562500  0.245283  0.251142  0.816794  0.129032    1.0    1.0   1.0   0.0   \n",
              "4  0.583333  0.245283  0.520548  0.702290  0.096774    1.0    0.0   0.0   0.0   \n",
              "\n",
              "   cp_3  ...  restecg_1  restecg_2  exang_1  ca_1  ca_2  ca_3  ca_4  thal_1  \\\n",
              "0   1.0  ...        0.0        0.0      0.0   0.0   0.0   0.0   0.0     1.0   \n",
              "1   0.0  ...        1.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "2   0.0  ...        0.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "3   0.0  ...        1.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "4   0.0  ...        1.0        0.0      1.0   0.0   0.0   0.0   0.0     0.0   \n",
              "\n",
              "   thal_2  thal_3  \n",
              "0     0.0     0.0  \n",
              "1     1.0     0.0  \n",
              "2     1.0     0.0  \n",
              "3     1.0     0.0  \n",
              "4     1.0     0.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee6c0bf9-fcbc-4a74-8eea-231caecac531\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>...</th>\n",
              "      <th>restecg_1</th>\n",
              "      <th>restecg_2</th>\n",
              "      <th>exang_1</th>\n",
              "      <th>ca_1</th>\n",
              "      <th>ca_2</th>\n",
              "      <th>ca_3</th>\n",
              "      <th>ca_4</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.481132</td>\n",
              "      <td>0.244292</td>\n",
              "      <td>0.603053</td>\n",
              "      <td>0.370968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.283105</td>\n",
              "      <td>0.885496</td>\n",
              "      <td>0.564516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.178082</td>\n",
              "      <td>0.770992</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.251142</td>\n",
              "      <td>0.816794</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.702290</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee6c0bf9-fcbc-4a74-8eea-231caecac531')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee6c0bf9-fcbc-4a74-8eea-231caecac531 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee6c0bf9-fcbc-4a74-8eea-231caecac531');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9b8eb2b5-3188-4f40-91d5-ecb77a18c1a1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b8eb2b5-3188-4f40-91d5-ecb77a18c1a1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9b8eb2b5-3188-4f40-91d5-ecb77a18c1a1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvykedw82t3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7b2218-4861-4a27-f4e2-5ea094bbe1d1"
      },
      "source": [
        "### 9. Modify the code to split the dataset into train and test (train 70%, val 20% and test 10%).\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "# re-create train and validation set\n",
        "x_train, x_val, y_train, y_val  = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "# train 70%, validation 20%, test 10%\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(217, 21)\n",
            "(55, 21)\n",
            "(31, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pwz5A_j2t30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca5bd7e-6d5f-4dca-a184-1d734d845a72"
      },
      "source": [
        "### 10. What is the purpose of each layer in the neural network created using the Sequential() function with 64, 32, and 1 neurons,\n",
        "### respectively, and softmax and sigmoid activation functions?\n",
        "\n",
        "model = Sequential() #Allow us to create model layer by layer\n",
        "model.add(Dense(64, input_dim=21, activation='softmax')) #Softmax turn number data into probabilities which sum to 1\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.add(Dense(1, activation='sigmoid')) # produce probability value (number between 0 or 1)\n",
        "model.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 64)                1408      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3521 (13.75 KB)\n",
            "Trainable params: 3521 (13.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0pM4z_OQfNi"
      },
      "source": [
        "### 11. This code compiles a neural network model with a mean squared error loss function, the Adam optimizer with a learning rate of 0.01,\n",
        "### and accuracy as a performance metric. What does each of these components mean, and how do they affect the model training and performance?\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999,epsilon=1e-07, amsgrad=False,name='Adam'),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unxSIBnZ2t36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c92fbb-0369-427d-f15e-c8187a9cbe00"
      },
      "source": [
        "# start the model training\n",
        "output = []\n",
        "early = EarlyStopping(monitor='val_acc', patience=400, mode='auto')\n",
        "checkpoint = ModelCheckpoint(model_loc+\"heart_disease_best_model.hdf5\", monitor='val_acc', verbose=0, save_best_only=True, mode='auto', save_freq='epoch')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.01, patience=100, verbose=1, mode='auto', min_lr=0.001)\n",
        "callbacks_list = [early]\n",
        "\n",
        "output = model.fit(x_train, y_train,validation_data=(x_val,y_val), epochs=1000, batch_size=16, verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "14/14 [==============================] - 1s 23ms/step - loss: 0.2500 - acc: 0.4793 - val_loss: 0.2482 - val_acc: 0.5455\n",
            "Epoch 2/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2473 - acc: 0.5438 - val_loss: 0.2454 - val_acc: 0.5455\n",
            "Epoch 3/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.2439 - acc: 0.5438 - val_loss: 0.2393 - val_acc: 0.5455\n",
            "Epoch 4/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2362 - acc: 0.5438 - val_loss: 0.2271 - val_acc: 0.6182\n",
            "Epoch 5/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2232 - acc: 0.7327 - val_loss: 0.2107 - val_acc: 0.8000\n",
            "Epoch 6/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2067 - acc: 0.8249 - val_loss: 0.1923 - val_acc: 0.8182\n",
            "Epoch 7/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1875 - acc: 0.8525 - val_loss: 0.1699 - val_acc: 0.8545\n",
            "Epoch 8/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1685 - acc: 0.8479 - val_loss: 0.1531 - val_acc: 0.8727\n",
            "Epoch 9/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1525 - acc: 0.8571 - val_loss: 0.1373 - val_acc: 0.8727\n",
            "Epoch 10/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1389 - acc: 0.8571 - val_loss: 0.1351 - val_acc: 0.8545\n",
            "Epoch 11/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1292 - acc: 0.8664 - val_loss: 0.1231 - val_acc: 0.8727\n",
            "Epoch 12/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1202 - acc: 0.8710 - val_loss: 0.1164 - val_acc: 0.8727\n",
            "Epoch 13/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1156 - acc: 0.8710 - val_loss: 0.1227 - val_acc: 0.8000\n",
            "Epoch 14/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1074 - acc: 0.8756 - val_loss: 0.1076 - val_acc: 0.8727\n",
            "Epoch 15/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1019 - acc: 0.8802 - val_loss: 0.1230 - val_acc: 0.7818\n",
            "Epoch 16/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0996 - acc: 0.8894 - val_loss: 0.1122 - val_acc: 0.8545\n",
            "Epoch 17/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0919 - acc: 0.9032 - val_loss: 0.1256 - val_acc: 0.8182\n",
            "Epoch 18/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0878 - acc: 0.9171 - val_loss: 0.1091 - val_acc: 0.8545\n",
            "Epoch 19/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0834 - acc: 0.9171 - val_loss: 0.1235 - val_acc: 0.8000\n",
            "Epoch 20/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0814 - acc: 0.9217 - val_loss: 0.1186 - val_acc: 0.8364\n",
            "Epoch 21/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0794 - acc: 0.9217 - val_loss: 0.1275 - val_acc: 0.8000\n",
            "Epoch 22/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0801 - acc: 0.9124 - val_loss: 0.1268 - val_acc: 0.8000\n",
            "Epoch 23/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0766 - acc: 0.9217 - val_loss: 0.1225 - val_acc: 0.8364\n",
            "Epoch 24/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0758 - acc: 0.9217 - val_loss: 0.1213 - val_acc: 0.8364\n",
            "Epoch 25/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0740 - acc: 0.9217 - val_loss: 0.1240 - val_acc: 0.8364\n",
            "Epoch 26/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0738 - acc: 0.9217 - val_loss: 0.1217 - val_acc: 0.8364\n",
            "Epoch 27/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0719 - acc: 0.9171 - val_loss: 0.1289 - val_acc: 0.8364\n",
            "Epoch 28/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0699 - acc: 0.9263 - val_loss: 0.1244 - val_acc: 0.8364\n",
            "Epoch 29/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0688 - acc: 0.9263 - val_loss: 0.1282 - val_acc: 0.8364\n",
            "Epoch 30/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0670 - acc: 0.9309 - val_loss: 0.1252 - val_acc: 0.8364\n",
            "Epoch 31/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0667 - acc: 0.9263 - val_loss: 0.1322 - val_acc: 0.8364\n",
            "Epoch 32/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0664 - acc: 0.9309 - val_loss: 0.1270 - val_acc: 0.8364\n",
            "Epoch 33/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0660 - acc: 0.9309 - val_loss: 0.1258 - val_acc: 0.8364\n",
            "Epoch 34/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0649 - acc: 0.9355 - val_loss: 0.1279 - val_acc: 0.8364\n",
            "Epoch 35/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0641 - acc: 0.9309 - val_loss: 0.1277 - val_acc: 0.8364\n",
            "Epoch 36/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0640 - acc: 0.9355 - val_loss: 0.1282 - val_acc: 0.8364\n",
            "Epoch 37/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0636 - acc: 0.9309 - val_loss: 0.1268 - val_acc: 0.8364\n",
            "Epoch 38/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0615 - acc: 0.9355 - val_loss: 0.1302 - val_acc: 0.8364\n",
            "Epoch 39/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0616 - acc: 0.9355 - val_loss: 0.1243 - val_acc: 0.8364\n",
            "Epoch 40/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0606 - acc: 0.9355 - val_loss: 0.1274 - val_acc: 0.8364\n",
            "Epoch 41/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0594 - acc: 0.9401 - val_loss: 0.1277 - val_acc: 0.8364\n",
            "Epoch 42/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0589 - acc: 0.9401 - val_loss: 0.1248 - val_acc: 0.8364\n",
            "Epoch 43/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0584 - acc: 0.9401 - val_loss: 0.1287 - val_acc: 0.8364\n",
            "Epoch 44/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0582 - acc: 0.9401 - val_loss: 0.1262 - val_acc: 0.8364\n",
            "Epoch 45/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0578 - acc: 0.9401 - val_loss: 0.1347 - val_acc: 0.8182\n",
            "Epoch 46/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0574 - acc: 0.9401 - val_loss: 0.1294 - val_acc: 0.8364\n",
            "Epoch 47/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0580 - acc: 0.9401 - val_loss: 0.1267 - val_acc: 0.8364\n",
            "Epoch 48/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0567 - acc: 0.9401 - val_loss: 0.1284 - val_acc: 0.8182\n",
            "Epoch 49/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0562 - acc: 0.9401 - val_loss: 0.1351 - val_acc: 0.8182\n",
            "Epoch 50/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0556 - acc: 0.9401 - val_loss: 0.1362 - val_acc: 0.8182\n",
            "Epoch 51/1000\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0555 - acc: 0.9401 - val_loss: 0.1400 - val_acc: 0.8182\n",
            "Epoch 52/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0548 - acc: 0.9401 - val_loss: 0.1356 - val_acc: 0.8182\n",
            "Epoch 53/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0549 - acc: 0.9401 - val_loss: 0.1413 - val_acc: 0.8182\n",
            "Epoch 54/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0530 - acc: 0.9401 - val_loss: 0.1252 - val_acc: 0.8364\n",
            "Epoch 55/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0531 - acc: 0.9401 - val_loss: 0.1348 - val_acc: 0.8364\n",
            "Epoch 56/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0528 - acc: 0.9401 - val_loss: 0.1318 - val_acc: 0.8364\n",
            "Epoch 57/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0528 - acc: 0.9401 - val_loss: 0.1408 - val_acc: 0.8364\n",
            "Epoch 58/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0512 - acc: 0.9447 - val_loss: 0.1342 - val_acc: 0.8364\n",
            "Epoch 59/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0513 - acc: 0.9447 - val_loss: 0.1382 - val_acc: 0.8364\n",
            "Epoch 60/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0501 - acc: 0.9447 - val_loss: 0.1361 - val_acc: 0.8364\n",
            "Epoch 61/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0480 - acc: 0.9493 - val_loss: 0.1373 - val_acc: 0.8364\n",
            "Epoch 62/1000\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0488 - acc: 0.9493 - val_loss: 0.1356 - val_acc: 0.8364\n",
            "Epoch 63/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0483 - acc: 0.9447 - val_loss: 0.1391 - val_acc: 0.8364\n",
            "Epoch 64/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0469 - acc: 0.9493 - val_loss: 0.1392 - val_acc: 0.8364\n",
            "Epoch 65/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0459 - acc: 0.9539 - val_loss: 0.1380 - val_acc: 0.8364\n",
            "Epoch 66/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0470 - acc: 0.9539 - val_loss: 0.1398 - val_acc: 0.8182\n",
            "Epoch 67/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0472 - acc: 0.9539 - val_loss: 0.1363 - val_acc: 0.8545\n",
            "Epoch 68/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0496 - acc: 0.9493 - val_loss: 0.1429 - val_acc: 0.8182\n",
            "Epoch 69/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0457 - acc: 0.9539 - val_loss: 0.1443 - val_acc: 0.8364\n",
            "Epoch 70/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0450 - acc: 0.9539 - val_loss: 0.1440 - val_acc: 0.8182\n",
            "Epoch 71/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0451 - acc: 0.9539 - val_loss: 0.1438 - val_acc: 0.8182\n",
            "Epoch 72/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0441 - acc: 0.9539 - val_loss: 0.1465 - val_acc: 0.8182\n",
            "Epoch 73/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0465 - acc: 0.9493 - val_loss: 0.1437 - val_acc: 0.8364\n",
            "Epoch 74/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0463 - acc: 0.9447 - val_loss: 0.1524 - val_acc: 0.8182\n",
            "Epoch 75/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0451 - acc: 0.9493 - val_loss: 0.1566 - val_acc: 0.8182\n",
            "Epoch 76/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0437 - acc: 0.9539 - val_loss: 0.1547 - val_acc: 0.8182\n",
            "Epoch 77/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0433 - acc: 0.9539 - val_loss: 0.1524 - val_acc: 0.8182\n",
            "Epoch 78/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0428 - acc: 0.9539 - val_loss: 0.1559 - val_acc: 0.8182\n",
            "Epoch 79/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0420 - acc: 0.9585 - val_loss: 0.1596 - val_acc: 0.8182\n",
            "Epoch 80/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0406 - acc: 0.9585 - val_loss: 0.1590 - val_acc: 0.8182\n",
            "Epoch 81/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0402 - acc: 0.9585 - val_loss: 0.1604 - val_acc: 0.8182\n",
            "Epoch 82/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0391 - acc: 0.9585 - val_loss: 0.1582 - val_acc: 0.8182\n",
            "Epoch 83/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0393 - acc: 0.9585 - val_loss: 0.1592 - val_acc: 0.8182\n",
            "Epoch 84/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0428 - acc: 0.9585 - val_loss: 0.1596 - val_acc: 0.8182\n",
            "Epoch 85/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0422 - acc: 0.9539 - val_loss: 0.1633 - val_acc: 0.8182\n",
            "Epoch 86/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0414 - acc: 0.9539 - val_loss: 0.1635 - val_acc: 0.8182\n",
            "Epoch 87/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0379 - acc: 0.9585 - val_loss: 0.1623 - val_acc: 0.8182\n",
            "Epoch 88/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0394 - acc: 0.9585 - val_loss: 0.1621 - val_acc: 0.8182\n",
            "Epoch 89/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0382 - acc: 0.9631 - val_loss: 0.1650 - val_acc: 0.8182\n",
            "Epoch 90/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0401 - acc: 0.9585 - val_loss: 0.1670 - val_acc: 0.8182\n",
            "Epoch 91/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0381 - acc: 0.9585 - val_loss: 0.1603 - val_acc: 0.8182\n",
            "Epoch 92/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0389 - acc: 0.9585 - val_loss: 0.1638 - val_acc: 0.8182\n",
            "Epoch 93/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0367 - acc: 0.9631 - val_loss: 0.1619 - val_acc: 0.8182\n",
            "Epoch 94/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0371 - acc: 0.9631 - val_loss: 0.1657 - val_acc: 0.8182\n",
            "Epoch 95/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0366 - acc: 0.9631 - val_loss: 0.1714 - val_acc: 0.8000\n",
            "Epoch 96/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0384 - acc: 0.9585 - val_loss: 0.1665 - val_acc: 0.8182\n",
            "Epoch 97/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0358 - acc: 0.9631 - val_loss: 0.1722 - val_acc: 0.8000\n",
            "Epoch 98/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0362 - acc: 0.9585 - val_loss: 0.1711 - val_acc: 0.8000\n",
            "Epoch 99/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0340 - acc: 0.9677 - val_loss: 0.1736 - val_acc: 0.8000\n",
            "Epoch 100/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0364 - acc: 0.9539 - val_loss: 0.1721 - val_acc: 0.8000\n",
            "Epoch 101/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0328 - acc: 0.9631 - val_loss: 0.1707 - val_acc: 0.8000\n",
            "Epoch 102/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0319 - acc: 0.9677 - val_loss: 0.1730 - val_acc: 0.8000\n",
            "Epoch 103/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0305 - acc: 0.9724 - val_loss: 0.1696 - val_acc: 0.8000\n",
            "Epoch 104/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0321 - acc: 0.9677 - val_loss: 0.1736 - val_acc: 0.8000\n",
            "Epoch 105/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0316 - acc: 0.9677 - val_loss: 0.1738 - val_acc: 0.8000\n",
            "Epoch 106/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0326 - acc: 0.9677 - val_loss: 0.1896 - val_acc: 0.7818\n",
            "Epoch 107/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0389 - acc: 0.9539 - val_loss: 0.1872 - val_acc: 0.7818\n",
            "Epoch 108/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0351 - acc: 0.9631 - val_loss: 0.1943 - val_acc: 0.7636\n",
            "Epoch 109/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0354 - acc: 0.9631 - val_loss: 0.1588 - val_acc: 0.8182\n",
            "Epoch 110/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0370 - acc: 0.9585 - val_loss: 0.1837 - val_acc: 0.7818\n",
            "Epoch 111/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0373 - acc: 0.9585 - val_loss: 0.1687 - val_acc: 0.8000\n",
            "Epoch 112/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0331 - acc: 0.9631 - val_loss: 0.1885 - val_acc: 0.7818\n",
            "Epoch 113/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0342 - acc: 0.9631 - val_loss: 0.1786 - val_acc: 0.7818\n",
            "Epoch 114/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0318 - acc: 0.9677 - val_loss: 0.1821 - val_acc: 0.7818\n",
            "Epoch 115/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0321 - acc: 0.9677 - val_loss: 0.1834 - val_acc: 0.7818\n",
            "Epoch 116/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0298 - acc: 0.9677 - val_loss: 0.1831 - val_acc: 0.7818\n",
            "Epoch 117/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0293 - acc: 0.9724 - val_loss: 0.1909 - val_acc: 0.7818\n",
            "Epoch 118/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0287 - acc: 0.9724 - val_loss: 0.1911 - val_acc: 0.7818\n",
            "Epoch 119/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0285 - acc: 0.9724 - val_loss: 0.1871 - val_acc: 0.7818\n",
            "Epoch 120/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0293 - acc: 0.9724 - val_loss: 0.1929 - val_acc: 0.7818\n",
            "Epoch 121/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0296 - acc: 0.9724 - val_loss: 0.1931 - val_acc: 0.7818\n",
            "Epoch 122/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0283 - acc: 0.9724 - val_loss: 0.1963 - val_acc: 0.7636\n",
            "Epoch 123/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0282 - acc: 0.9724 - val_loss: 0.1919 - val_acc: 0.7818\n",
            "Epoch 124/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0280 - acc: 0.9724 - val_loss: 0.1962 - val_acc: 0.7636\n",
            "Epoch 125/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0280 - acc: 0.9724 - val_loss: 0.1908 - val_acc: 0.7818\n",
            "Epoch 126/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0278 - acc: 0.9724 - val_loss: 0.1967 - val_acc: 0.7636\n",
            "Epoch 127/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0279 - acc: 0.9724 - val_loss: 0.1947 - val_acc: 0.7818\n",
            "Epoch 128/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0278 - acc: 0.9724 - val_loss: 0.1975 - val_acc: 0.7636\n",
            "Epoch 129/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0278 - acc: 0.9724 - val_loss: 0.1954 - val_acc: 0.7818\n",
            "Epoch 130/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0277 - acc: 0.9724 - val_loss: 0.1984 - val_acc: 0.7636\n",
            "Epoch 131/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0279 - acc: 0.9724 - val_loss: 0.1964 - val_acc: 0.7818\n",
            "Epoch 132/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0279 - acc: 0.9724 - val_loss: 0.1978 - val_acc: 0.7636\n",
            "Epoch 133/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0279 - acc: 0.9724 - val_loss: 0.1955 - val_acc: 0.7818\n",
            "Epoch 134/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0277 - acc: 0.9724 - val_loss: 0.1973 - val_acc: 0.7636\n",
            "Epoch 135/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0276 - acc: 0.9724 - val_loss: 0.1983 - val_acc: 0.7636\n",
            "Epoch 136/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0276 - acc: 0.9724 - val_loss: 0.1983 - val_acc: 0.7636\n",
            "Epoch 137/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0276 - acc: 0.9724 - val_loss: 0.1978 - val_acc: 0.7636\n",
            "Epoch 138/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0275 - acc: 0.9724 - val_loss: 0.1999 - val_acc: 0.7636\n",
            "Epoch 139/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0276 - acc: 0.9724 - val_loss: 0.1977 - val_acc: 0.7636\n",
            "Epoch 140/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0275 - acc: 0.9724 - val_loss: 0.2000 - val_acc: 0.7636\n",
            "Epoch 141/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0275 - acc: 0.9724 - val_loss: 0.2000 - val_acc: 0.7636\n",
            "Epoch 142/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0275 - acc: 0.9724 - val_loss: 0.1983 - val_acc: 0.7636\n",
            "Epoch 143/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0275 - acc: 0.9724 - val_loss: 0.2002 - val_acc: 0.7636\n",
            "Epoch 144/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0276 - acc: 0.9724 - val_loss: 0.2011 - val_acc: 0.7636\n",
            "Epoch 145/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0275 - acc: 0.9724 - val_loss: 0.1981 - val_acc: 0.7636\n",
            "Epoch 146/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0274 - acc: 0.9724 - val_loss: 0.2002 - val_acc: 0.7636\n",
            "Epoch 147/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0274 - acc: 0.9724 - val_loss: 0.2009 - val_acc: 0.7636\n",
            "Epoch 148/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0273 - acc: 0.9724 - val_loss: 0.2011 - val_acc: 0.7636\n",
            "Epoch 149/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0274 - acc: 0.9724 - val_loss: 0.2017 - val_acc: 0.7636\n",
            "Epoch 150/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0274 - acc: 0.9724 - val_loss: 0.2024 - val_acc: 0.7636\n",
            "Epoch 151/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0274 - acc: 0.9724 - val_loss: 0.1993 - val_acc: 0.7636\n",
            "Epoch 152/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0273 - acc: 0.9724 - val_loss: 0.2022 - val_acc: 0.7636\n",
            "Epoch 153/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0273 - acc: 0.9724 - val_loss: 0.2006 - val_acc: 0.7636\n",
            "Epoch 154/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0273 - acc: 0.9724 - val_loss: 0.2011 - val_acc: 0.7636\n",
            "Epoch 155/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0273 - acc: 0.9724 - val_loss: 0.2020 - val_acc: 0.7636\n",
            "Epoch 156/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0273 - acc: 0.9724 - val_loss: 0.2018 - val_acc: 0.7636\n",
            "Epoch 157/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0273 - acc: 0.9724 - val_loss: 0.2007 - val_acc: 0.7636\n",
            "Epoch 158/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0273 - acc: 0.9724 - val_loss: 0.2022 - val_acc: 0.7636\n",
            "Epoch 159/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0272 - acc: 0.9724 - val_loss: 0.2013 - val_acc: 0.7636\n",
            "Epoch 160/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0272 - acc: 0.9724 - val_loss: 0.2019 - val_acc: 0.7636\n",
            "Epoch 161/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0272 - acc: 0.9724 - val_loss: 0.2015 - val_acc: 0.7636\n",
            "Epoch 162/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0272 - acc: 0.9724 - val_loss: 0.2026 - val_acc: 0.7636\n",
            "Epoch 163/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0272 - acc: 0.9724 - val_loss: 0.2016 - val_acc: 0.7636\n",
            "Epoch 164/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0272 - acc: 0.9724 - val_loss: 0.2025 - val_acc: 0.7636\n",
            "Epoch 165/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0272 - acc: 0.9724 - val_loss: 0.2014 - val_acc: 0.7636\n",
            "Epoch 166/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0272 - acc: 0.9724 - val_loss: 0.2015 - val_acc: 0.7636\n",
            "Epoch 167/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0271 - acc: 0.9724 - val_loss: 0.2021 - val_acc: 0.7636\n",
            "Epoch 168/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0272 - acc: 0.9724 - val_loss: 0.2015 - val_acc: 0.7636\n",
            "Epoch 169/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0271 - acc: 0.9724 - val_loss: 0.2016 - val_acc: 0.7636\n",
            "Epoch 170/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0271 - acc: 0.9724 - val_loss: 0.2021 - val_acc: 0.7636\n",
            "Epoch 171/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0272 - acc: 0.9724 - val_loss: 0.2023 - val_acc: 0.7636\n",
            "Epoch 172/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0271 - acc: 0.9724 - val_loss: 0.2013 - val_acc: 0.7636\n",
            "Epoch 173/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0271 - acc: 0.9724 - val_loss: 0.2023 - val_acc: 0.7636\n",
            "Epoch 174/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0271 - acc: 0.9724 - val_loss: 0.2014 - val_acc: 0.7636\n",
            "Epoch 175/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0271 - acc: 0.9724 - val_loss: 0.2031 - val_acc: 0.7636\n",
            "Epoch 176/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0271 - acc: 0.9724 - val_loss: 0.2016 - val_acc: 0.7636\n",
            "Epoch 177/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2011 - val_acc: 0.7636\n",
            "Epoch 178/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2019 - val_acc: 0.7636\n",
            "Epoch 179/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0271 - acc: 0.9724 - val_loss: 0.2011 - val_acc: 0.7636\n",
            "Epoch 180/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2017 - val_acc: 0.7636\n",
            "Epoch 181/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2009 - val_acc: 0.7636\n",
            "Epoch 182/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2017 - val_acc: 0.7636\n",
            "Epoch 183/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2014 - val_acc: 0.7636\n",
            "Epoch 184/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2010 - val_acc: 0.7636\n",
            "Epoch 185/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2012 - val_acc: 0.7636\n",
            "Epoch 186/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2013 - val_acc: 0.7636\n",
            "Epoch 187/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2015 - val_acc: 0.7636\n",
            "Epoch 188/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2006 - val_acc: 0.7636\n",
            "Epoch 189/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2009 - val_acc: 0.7636\n",
            "Epoch 190/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2018 - val_acc: 0.7636\n",
            "Epoch 191/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.2003 - val_acc: 0.7636\n",
            "Epoch 192/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.2002 - val_acc: 0.7636\n",
            "Epoch 193/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.2001 - val_acc: 0.7636\n",
            "Epoch 194/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2006 - val_acc: 0.7636\n",
            "Epoch 195/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.1995 - val_acc: 0.7636\n",
            "Epoch 196/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.2009 - val_acc: 0.7636\n",
            "Epoch 197/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.2008 - val_acc: 0.7636\n",
            "Epoch 198/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.2002 - val_acc: 0.7636\n",
            "Epoch 199/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0270 - acc: 0.9724 - val_loss: 0.2000 - val_acc: 0.7636\n",
            "Epoch 200/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.1997 - val_acc: 0.7636\n",
            "Epoch 201/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.2000 - val_acc: 0.7636\n",
            "Epoch 202/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.1999 - val_acc: 0.7636\n",
            "Epoch 203/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.1998 - val_acc: 0.7636\n",
            "Epoch 204/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.1996 - val_acc: 0.7636\n",
            "Epoch 205/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1992 - val_acc: 0.7636\n",
            "Epoch 206/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.2001 - val_acc: 0.7636\n",
            "Epoch 207/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0269 - acc: 0.9724 - val_loss: 0.2000 - val_acc: 0.7636\n",
            "Epoch 208/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1997 - val_acc: 0.7636\n",
            "Epoch 209/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1995 - val_acc: 0.7636\n",
            "Epoch 210/1000\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1991 - val_acc: 0.7636\n",
            "Epoch 211/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1996 - val_acc: 0.7636\n",
            "Epoch 212/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1995 - val_acc: 0.7636\n",
            "Epoch 213/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1996 - val_acc: 0.7636\n",
            "Epoch 214/1000\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1992 - val_acc: 0.7636\n",
            "Epoch 215/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1991 - val_acc: 0.7636\n",
            "Epoch 216/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1989 - val_acc: 0.7636\n",
            "Epoch 217/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1997 - val_acc: 0.7818\n",
            "Epoch 218/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1981 - val_acc: 0.7636\n",
            "Epoch 219/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1989 - val_acc: 0.7636\n",
            "Epoch 220/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0267 - acc: 0.9724 - val_loss: 0.1990 - val_acc: 0.7636\n",
            "Epoch 221/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0267 - acc: 0.9724 - val_loss: 0.1993 - val_acc: 0.7636\n",
            "Epoch 222/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0267 - acc: 0.9724 - val_loss: 0.1990 - val_acc: 0.7818\n",
            "Epoch 223/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0267 - acc: 0.9724 - val_loss: 0.1989 - val_acc: 0.7636\n",
            "Epoch 224/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0267 - acc: 0.9724 - val_loss: 0.1988 - val_acc: 0.7818\n",
            "Epoch 225/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0267 - acc: 0.9724 - val_loss: 0.1987 - val_acc: 0.7818\n",
            "Epoch 226/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1984 - val_acc: 0.7636\n",
            "Epoch 227/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0267 - acc: 0.9724 - val_loss: 0.1992 - val_acc: 0.7818\n",
            "Epoch 228/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0268 - acc: 0.9724 - val_loss: 0.1995 - val_acc: 0.7636\n",
            "Epoch 229/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0266 - acc: 0.9724 - val_loss: 0.1996 - val_acc: 0.7818\n",
            "Epoch 230/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0266 - acc: 0.9724 - val_loss: 0.1991 - val_acc: 0.7818\n",
            "Epoch 231/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0266 - acc: 0.9724 - val_loss: 0.1972 - val_acc: 0.7818\n",
            "Epoch 232/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0265 - acc: 0.9724 - val_loss: 0.1977 - val_acc: 0.7818\n",
            "Epoch 233/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0263 - acc: 0.9724 - val_loss: 0.1975 - val_acc: 0.7818\n",
            "Epoch 234/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0259 - acc: 0.9724 - val_loss: 0.1971 - val_acc: 0.7818\n",
            "Epoch 235/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0256 - acc: 0.9724 - val_loss: 0.1961 - val_acc: 0.7818\n",
            "Epoch 236/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0249 - acc: 0.9724 - val_loss: 0.1956 - val_acc: 0.7818\n",
            "Epoch 237/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0243 - acc: 0.9724 - val_loss: 0.1957 - val_acc: 0.7818\n",
            "Epoch 238/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0237 - acc: 0.9724 - val_loss: 0.1951 - val_acc: 0.7818\n",
            "Epoch 239/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0230 - acc: 0.9724 - val_loss: 0.1945 - val_acc: 0.7818\n",
            "Epoch 240/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0221 - acc: 0.9724 - val_loss: 0.1934 - val_acc: 0.7818\n",
            "Epoch 241/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0215 - acc: 0.9724 - val_loss: 0.1941 - val_acc: 0.7818\n",
            "Epoch 242/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0213 - acc: 0.9724 - val_loss: 0.1924 - val_acc: 0.7818\n",
            "Epoch 243/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0203 - acc: 0.9724 - val_loss: 0.1930 - val_acc: 0.7818\n",
            "Epoch 244/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0196 - acc: 0.9724 - val_loss: 0.1925 - val_acc: 0.7818\n",
            "Epoch 245/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0188 - acc: 0.9724 - val_loss: 0.1917 - val_acc: 0.7818\n",
            "Epoch 246/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0189 - acc: 0.9862 - val_loss: 0.1936 - val_acc: 0.7818\n",
            "Epoch 247/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0182 - acc: 0.9724 - val_loss: 0.1915 - val_acc: 0.7818\n",
            "Epoch 248/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0168 - acc: 0.9862 - val_loss: 0.1937 - val_acc: 0.7818\n",
            "Epoch 249/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0165 - acc: 0.9862 - val_loss: 0.1922 - val_acc: 0.7818\n",
            "Epoch 250/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0161 - acc: 0.9862 - val_loss: 0.1917 - val_acc: 0.7818\n",
            "Epoch 251/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0158 - acc: 0.9862 - val_loss: 0.1930 - val_acc: 0.7818\n",
            "Epoch 252/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0155 - acc: 0.9862 - val_loss: 0.1933 - val_acc: 0.7818\n",
            "Epoch 253/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0155 - acc: 0.9862 - val_loss: 0.1945 - val_acc: 0.7818\n",
            "Epoch 254/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0152 - acc: 0.9862 - val_loss: 0.1935 - val_acc: 0.7818\n",
            "Epoch 255/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0150 - acc: 0.9862 - val_loss: 0.1939 - val_acc: 0.7818\n",
            "Epoch 256/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0148 - acc: 0.9862 - val_loss: 0.1938 - val_acc: 0.7818\n",
            "Epoch 257/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0147 - acc: 0.9862 - val_loss: 0.1949 - val_acc: 0.7818\n",
            "Epoch 258/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0146 - acc: 0.9862 - val_loss: 0.1935 - val_acc: 0.7818\n",
            "Epoch 259/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0145 - acc: 0.9862 - val_loss: 0.1943 - val_acc: 0.7818\n",
            "Epoch 260/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0144 - acc: 0.9862 - val_loss: 0.1950 - val_acc: 0.7818\n",
            "Epoch 261/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0144 - acc: 0.9862 - val_loss: 0.1953 - val_acc: 0.7818\n",
            "Epoch 262/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0143 - acc: 0.9862 - val_loss: 0.1952 - val_acc: 0.7818\n",
            "Epoch 263/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0143 - acc: 0.9862 - val_loss: 0.1952 - val_acc: 0.7818\n",
            "Epoch 264/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0142 - acc: 0.9862 - val_loss: 0.1947 - val_acc: 0.7818\n",
            "Epoch 265/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0142 - acc: 0.9862 - val_loss: 0.1964 - val_acc: 0.7818\n",
            "Epoch 266/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0141 - acc: 0.9862 - val_loss: 0.1951 - val_acc: 0.7818\n",
            "Epoch 267/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0141 - acc: 0.9862 - val_loss: 0.1955 - val_acc: 0.7818\n",
            "Epoch 268/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0141 - acc: 0.9862 - val_loss: 0.1963 - val_acc: 0.7818\n",
            "Epoch 269/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0140 - acc: 0.9862 - val_loss: 0.1956 - val_acc: 0.7818\n",
            "Epoch 270/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0140 - acc: 0.9862 - val_loss: 0.1964 - val_acc: 0.7818\n",
            "Epoch 271/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0140 - acc: 0.9862 - val_loss: 0.1961 - val_acc: 0.7818\n",
            "Epoch 272/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0140 - acc: 0.9862 - val_loss: 0.1966 - val_acc: 0.7818\n",
            "Epoch 273/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0140 - acc: 0.9862 - val_loss: 0.1946 - val_acc: 0.7818\n",
            "Epoch 274/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0139 - acc: 0.9862 - val_loss: 0.1957 - val_acc: 0.7818\n",
            "Epoch 275/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0139 - acc: 0.9862 - val_loss: 0.1968 - val_acc: 0.7818\n",
            "Epoch 276/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0139 - acc: 0.9862 - val_loss: 0.1963 - val_acc: 0.7818\n",
            "Epoch 277/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0139 - acc: 0.9862 - val_loss: 0.1961 - val_acc: 0.7818\n",
            "Epoch 278/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0139 - acc: 0.9862 - val_loss: 0.1960 - val_acc: 0.7818\n",
            "Epoch 279/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0139 - acc: 0.9862 - val_loss: 0.1948 - val_acc: 0.7818\n",
            "Epoch 280/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0138 - acc: 0.9862 - val_loss: 0.1977 - val_acc: 0.7818\n",
            "Epoch 281/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0138 - acc: 0.9862 - val_loss: 0.1969 - val_acc: 0.7818\n",
            "Epoch 282/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0138 - acc: 0.9862 - val_loss: 0.1960 - val_acc: 0.7818\n",
            "Epoch 283/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0138 - acc: 0.9862 - val_loss: 0.1959 - val_acc: 0.7818\n",
            "Epoch 284/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0138 - acc: 0.9862 - val_loss: 0.1963 - val_acc: 0.7818\n",
            "Epoch 285/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0138 - acc: 0.9862 - val_loss: 0.1964 - val_acc: 0.7818\n",
            "Epoch 286/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0138 - acc: 0.9862 - val_loss: 0.1973 - val_acc: 0.7818\n",
            "Epoch 287/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0138 - acc: 0.9862 - val_loss: 0.1963 - val_acc: 0.7818\n",
            "Epoch 288/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0138 - acc: 0.9862 - val_loss: 0.1964 - val_acc: 0.7818\n",
            "Epoch 289/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0138 - acc: 0.9862 - val_loss: 0.1960 - val_acc: 0.7818\n",
            "Epoch 290/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1972 - val_acc: 0.7818\n",
            "Epoch 291/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1954 - val_acc: 0.7818\n",
            "Epoch 292/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1970 - val_acc: 0.7818\n",
            "Epoch 293/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1964 - val_acc: 0.7818\n",
            "Epoch 294/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1955 - val_acc: 0.7818\n",
            "Epoch 295/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1969 - val_acc: 0.7818\n",
            "Epoch 296/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1963 - val_acc: 0.7818\n",
            "Epoch 297/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1962 - val_acc: 0.7818\n",
            "Epoch 298/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1957 - val_acc: 0.7818\n",
            "Epoch 299/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1969 - val_acc: 0.7818\n",
            "Epoch 300/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1951 - val_acc: 0.7818\n",
            "Epoch 301/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1957 - val_acc: 0.7818\n",
            "Epoch 302/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0137 - acc: 0.9862 - val_loss: 0.1948 - val_acc: 0.7818\n",
            "Epoch 303/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1965 - val_acc: 0.7818\n",
            "Epoch 304/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1960 - val_acc: 0.7818\n",
            "Epoch 305/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1950 - val_acc: 0.7818\n",
            "Epoch 306/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1956 - val_acc: 0.7818\n",
            "Epoch 307/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1964 - val_acc: 0.7818\n",
            "Epoch 308/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1951 - val_acc: 0.7818\n",
            "Epoch 309/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1955 - val_acc: 0.7818\n",
            "Epoch 310/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1950 - val_acc: 0.7818\n",
            "Epoch 311/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1943 - val_acc: 0.7818\n",
            "Epoch 312/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1938 - val_acc: 0.7818\n",
            "Epoch 313/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1954 - val_acc: 0.7818\n",
            "Epoch 314/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1941 - val_acc: 0.7818\n",
            "Epoch 315/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1940 - val_acc: 0.7818\n",
            "Epoch 316/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1940 - val_acc: 0.7818\n",
            "Epoch 317/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1934 - val_acc: 0.7818\n",
            "Epoch 318/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0136 - acc: 0.9862 - val_loss: 0.1940 - val_acc: 0.7818\n",
            "Epoch 319/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1938 - val_acc: 0.7818\n",
            "Epoch 320/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1935 - val_acc: 0.8000\n",
            "Epoch 321/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1923 - val_acc: 0.8000\n",
            "Epoch 322/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1932 - val_acc: 0.8000\n",
            "Epoch 323/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1926 - val_acc: 0.8000\n",
            "Epoch 324/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1926 - val_acc: 0.8000\n",
            "Epoch 325/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1911 - val_acc: 0.8000\n",
            "Epoch 326/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1916 - val_acc: 0.8000\n",
            "Epoch 327/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1918 - val_acc: 0.8000\n",
            "Epoch 328/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1910 - val_acc: 0.8000\n",
            "Epoch 329/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1914 - val_acc: 0.8000\n",
            "Epoch 330/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1904 - val_acc: 0.8000\n",
            "Epoch 331/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1902 - val_acc: 0.8000\n",
            "Epoch 332/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1903 - val_acc: 0.8000\n",
            "Epoch 333/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1896 - val_acc: 0.8000\n",
            "Epoch 334/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1888 - val_acc: 0.8000\n",
            "Epoch 335/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1890 - val_acc: 0.8000\n",
            "Epoch 336/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1887 - val_acc: 0.8000\n",
            "Epoch 337/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0135 - acc: 0.9862 - val_loss: 0.1884 - val_acc: 0.8000\n",
            "Epoch 338/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1884 - val_acc: 0.8000\n",
            "Epoch 339/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1877 - val_acc: 0.8000\n",
            "Epoch 340/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1875 - val_acc: 0.8000\n",
            "Epoch 341/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1875 - val_acc: 0.8000\n",
            "Epoch 342/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1869 - val_acc: 0.8000\n",
            "Epoch 343/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1867 - val_acc: 0.8000\n",
            "Epoch 344/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1863 - val_acc: 0.8000\n",
            "Epoch 345/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1862 - val_acc: 0.8000\n",
            "Epoch 346/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1861 - val_acc: 0.8000\n",
            "Epoch 347/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1857 - val_acc: 0.8000\n",
            "Epoch 348/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1854 - val_acc: 0.8000\n",
            "Epoch 349/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1854 - val_acc: 0.8000\n",
            "Epoch 350/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1847 - val_acc: 0.8000\n",
            "Epoch 351/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1848 - val_acc: 0.8000\n",
            "Epoch 352/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1845 - val_acc: 0.8000\n",
            "Epoch 353/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1839 - val_acc: 0.8000\n",
            "Epoch 354/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0134 - acc: 0.9862 - val_loss: 0.1827 - val_acc: 0.8000\n",
            "Epoch 355/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1826 - val_acc: 0.8000\n",
            "Epoch 356/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1819 - val_acc: 0.8000\n",
            "Epoch 357/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1818 - val_acc: 0.8000\n",
            "Epoch 358/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1810 - val_acc: 0.8000\n",
            "Epoch 359/1000\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1811 - val_acc: 0.8000\n",
            "Epoch 360/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1806 - val_acc: 0.8000\n",
            "Epoch 361/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1787 - val_acc: 0.8000\n",
            "Epoch 362/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1788 - val_acc: 0.8000\n",
            "Epoch 363/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1780 - val_acc: 0.8000\n",
            "Epoch 364/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1764 - val_acc: 0.8000\n",
            "Epoch 365/1000\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1744 - val_acc: 0.8182\n",
            "Epoch 366/1000\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1736 - val_acc: 0.8182\n",
            "Epoch 367/1000\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1721 - val_acc: 0.8182\n",
            "Epoch 368/1000\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1710 - val_acc: 0.8182\n",
            "Epoch 369/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1715 - val_acc: 0.8182\n",
            "Epoch 370/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1701 - val_acc: 0.8182\n",
            "Epoch 371/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1690 - val_acc: 0.8182\n",
            "Epoch 372/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1683 - val_acc: 0.8182\n",
            "Epoch 373/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1668 - val_acc: 0.8182\n",
            "Epoch 374/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1656 - val_acc: 0.8182\n",
            "Epoch 375/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0133 - acc: 0.9862 - val_loss: 0.1664 - val_acc: 0.8182\n",
            "Epoch 376/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1650 - val_acc: 0.8182\n",
            "Epoch 377/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1651 - val_acc: 0.8182\n",
            "Epoch 378/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1630 - val_acc: 0.8364\n",
            "Epoch 379/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1630 - val_acc: 0.8364\n",
            "Epoch 380/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1633 - val_acc: 0.8182\n",
            "Epoch 381/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1608 - val_acc: 0.8364\n",
            "Epoch 382/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1606 - val_acc: 0.8364\n",
            "Epoch 383/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1608 - val_acc: 0.8364\n",
            "Epoch 384/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1598 - val_acc: 0.8364\n",
            "Epoch 385/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0131 - acc: 0.9862 - val_loss: 0.1596 - val_acc: 0.8364\n",
            "Epoch 386/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0131 - acc: 0.9862 - val_loss: 0.1593 - val_acc: 0.8364\n",
            "Epoch 387/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0131 - acc: 0.9862 - val_loss: 0.1592 - val_acc: 0.8364\n",
            "Epoch 388/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0131 - acc: 0.9862 - val_loss: 0.1594 - val_acc: 0.8364\n",
            "Epoch 389/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0132 - acc: 0.9862 - val_loss: 0.1597 - val_acc: 0.8364\n",
            "Epoch 390/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0131 - acc: 0.9862 - val_loss: 0.1590 - val_acc: 0.8364\n",
            "Epoch 391/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0131 - acc: 0.9862 - val_loss: 0.1579 - val_acc: 0.8364\n",
            "Epoch 392/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0131 - acc: 0.9862 - val_loss: 0.1588 - val_acc: 0.8364\n",
            "Epoch 393/1000\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0131 - acc: 0.9862 - val_loss: 0.1588 - val_acc: 0.8182\n",
            "Epoch 394/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0131 - acc: 0.9862 - val_loss: 0.1573 - val_acc: 0.8364\n",
            "Epoch 395/1000\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0131 - acc: 0.9862 - val_loss: 0.1572 - val_acc: 0.8364\n",
            "Epoch 396/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0130 - acc: 0.9862 - val_loss: 0.1581 - val_acc: 0.8182\n",
            "Epoch 397/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0130 - acc: 0.9862 - val_loss: 0.1578 - val_acc: 0.8182\n",
            "Epoch 398/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0130 - acc: 0.9862 - val_loss: 0.1575 - val_acc: 0.8182\n",
            "Epoch 399/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0130 - acc: 0.9862 - val_loss: 0.1583 - val_acc: 0.8182\n",
            "Epoch 400/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0130 - acc: 0.9862 - val_loss: 0.1582 - val_acc: 0.8182\n",
            "Epoch 401/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0130 - acc: 0.9862 - val_loss: 0.1572 - val_acc: 0.8182\n",
            "Epoch 402/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0129 - acc: 0.9862 - val_loss: 0.1562 - val_acc: 0.8182\n",
            "Epoch 403/1000\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0129 - acc: 0.9862 - val_loss: 0.1553 - val_acc: 0.8364\n",
            "Epoch 404/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0129 - acc: 0.9862 - val_loss: 0.1542 - val_acc: 0.8364\n",
            "Epoch 405/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0128 - acc: 0.9862 - val_loss: 0.1540 - val_acc: 0.8364\n",
            "Epoch 406/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0128 - acc: 0.9862 - val_loss: 0.1545 - val_acc: 0.8364\n",
            "Epoch 407/1000\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0127 - acc: 0.9862 - val_loss: 0.1535 - val_acc: 0.8364\n",
            "Epoch 408/1000\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0127 - acc: 0.9862 - val_loss: 0.1514 - val_acc: 0.8364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sYpy54d2t4H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "29a14748-777b-4686-9480-d886eee1951e"
      },
      "source": [
        "### 12. What does the plot generated by this code represent?\n",
        "\n",
        "plt.plot(output.history['acc'])\n",
        "plt.plot(output.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "#plt.savefig('Accuracy.png',dpi=100) #to save the image\n",
        "plt.show()\n",
        "\n",
        "## show the accuracy by using two different data which is the train and test for the model\n",
        "## as we can see that test set has lower accuracy compare to train set"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABa3UlEQVR4nO3deVxU5eIG8Gd2dhBZRQTcUBNxS0OtLElS85aVqS0ulf4yvalk5ZJa1pVupVczy7o3W27dtExt0SzDrZTcUnM3ccGNTWXfZ97fH8MMDAwIw8ycmeH5fj7zYThzzpn3ZZDz+C7nlQkhBIiIiIhchFzqAhARERFZE8MNERERuRSGGyIiInIpDDdERETkUhhuiIiIyKUw3BAREZFLYbghIiIil8JwQ0RERC6F4YaIiIhcCsMNEVnN+fPnIZPJ8MknnzT62O3bt0Mmk2H79u1WLxcRNS8MN0RERORSGG6IiIjIpTDcEBHZUGFhodRFIGp2GG6IXMgrr7wCmUyG06dP4/HHH4evry8CAwMxb948CCFw8eJF3H///fDx8UFISAgWL15c6xyZmZl46qmnEBwcDDc3N8TGxuLTTz+ttV9OTg7Gjx8PX19f+Pn5Ydy4ccjJyTFbrpMnT+Lhhx+Gv78/3Nzc0Lt3b3z33XcW1fHChQt49tlnER0dDXd3d7Rs2RIjR47E+fPnzZZxxowZiIyMhEajQevWrTF27FhkZ2cb9ykpKcErr7yCjh07ws3NDaGhoXjwwQeRmpoKoO6xQObGF40fPx5eXl5ITU3F0KFD4e3tjcceewwA8Ouvv2LkyJFo06YNNBoNwsPDMWPGDBQXF5v9eT3yyCMIDAyEu7s7oqOjMXfuXADAtm3bIJPJsH79+lrH/e9//4NMJkNKSkpjf6xELkUpdQGIyPpGjRqFzp0744033sDGjRvx+uuvw9/fHx988AHuvvtu/POf/8QXX3yBmTNn4tZbb8Udd9wBACguLsbAgQNx5swZTJ06FVFRUfj6668xfvx45OTkYNq0aQAAIQTuv/9+/Pbbb3jmmWfQuXNnrF+/HuPGjatVlmPHjqF///4ICwvDrFmz4Onpia+++goPPPAAvvnmG4wYMaJRddu3bx92796N0aNHo3Xr1jh//jzef/99DBw4EMePH4eHhwcAoKCgALfffjtOnDiBJ598Ej179kR2dja+++47XLp0CQEBAdBqtbjvvvuQnJyM0aNHY9q0acjPz8eWLVtw9OhRtGvXrtE/+4qKCiQkJGDAgAF4++23jeX5+uuvUVRUhMmTJ6Nly5bYu3cvli9fjkuXLuHrr782Hv/nn3/i9ttvh0qlwqRJkxAZGYnU1FR8//33+Mc//oGBAwciPDwcX3zxRa2f3RdffIF27dohLi6u0eUmcimCiFzGggULBAAxadIk47aKigrRunVrIZPJxBtvvGHcfuPGDeHu7i7GjRtn3LZ06VIBQHz++efGbWVlZSIuLk54eXmJvLw8IYQQGzZsEADEm2++afI+t99+uwAgPv74Y+P2QYMGiZiYGFFSUmLcptPpRL9+/USHDh2M27Zt2yYAiG3bttVbx6KiolrbUlJSBADx2WefGbfNnz9fABDr1q2rtb9OpxNCCLFq1SoBQCxZsqTOfeoq17lz52rVddy4cQKAmDVrVoPKnZSUJGQymbhw4YJx2x133CG8vb1NtlUvjxBCzJ49W2g0GpGTk2PclpmZKZRKpViwYEGt9yFqbtgtReSCnn76aeNzhUKB3r17QwiBp556yrjdz88P0dHROHv2rHHbpk2bEBISgjFjxhi3qVQqPPfccygoKMCOHTuM+ymVSkyePNnkff7+97+blOP69evYunUrHnnkEeTn5yM7OxvZ2dm4du0aEhIS8Ndff+Hy5cuNqpu7u7vxeXl5Oa5du4b27dvDz88Pf/zxh/G1b775BrGxsWZbhmQymXGfgICAWuWuvo8lqv9czJW7sLAQ2dnZ6NevH4QQOHjwIAAgKysLO3fuxJNPPok2bdrUWZ6xY8eitLQUa9euNW5bs2YNKioq8Pjjj1tcbiJXwXBD5IJqXhh9fX3h5uaGgICAWttv3Lhh/P7ChQvo0KED5HLTPw2dO3c2vm74GhoaCi8vL5P9oqOjTb4/c+YMhBCYN28eAgMDTR4LFiwAoB/j0xjFxcWYP38+wsPDodFoEBAQgMDAQOTk5CA3N9e4X2pqKrp27VrvuVJTUxEdHQ2l0no99EqlEq1bt661PS0tDePHj4e/vz+8vLwQGBiIO++8EwCM5TYEzZuVu1OnTrj11lvxxRdfGLd98cUXuO2229C+fXtrVYXIaXHMDZELUigUDdoG6MfP2IpOpwMAzJw5EwkJCWb3aezF+O9//zs+/vhjTJ8+HXFxcfD19YVMJsPo0aON72dNdbXgaLVas9s1Gk2tcKjVanHPPffg+vXreOmll9CpUyd4enri8uXLGD9+vEXlHjt2LKZNm4ZLly6htLQUv//+O959991Gn4fIFTHcEJFRREQE/vzzT+h0OpML9MmTJ42vG74mJyejoKDApPXm1KlTJudr27YtAH3XVnx8vFXKuHbtWowbN85kpldJSUmtmVrt2rXD0aNH6z1Xu3btsGfPHpSXl0OlUpndp0WLFgBQ6/yGVqyGOHLkCE6fPo1PP/0UY8eONW7fsmWLyX6Gn9fNyg0Ao0ePRmJiIr788ksUFxdDpVJh1KhRDS4TkStjtxQRGQ0dOhTp6elYs2aNcVtFRQWWL18OLy8vYzfK0KFDUVFRgffff9+4n1arxfLly03OFxQUhIEDB+KDDz7A1atXa71fVlZWo8uoUChqtTYtX768VkvKQw89hMOHD5udMm04/qGHHkJ2drbZFg/DPhEREVAoFNi5c6fJ6++9916jylz9nIbny5YtM9kvMDAQd9xxB1atWoW0tDSz5TEICAjAkCFD8Pnnn+OLL77AvffeW6vbkai5YssNERlNmjQJH3zwAcaPH48DBw4gMjISa9euxa5du7B06VJ4e3sDAIYPH47+/ftj1qxZOH/+PLp06YJ169aZjHkxWLFiBQYMGICYmBhMnDgRbdu2RUZGBlJSUnDp0iUcPny4UWW877778N///he+vr7o0qULUlJS8Msvv6Bly5Ym+73wwgtYu3YtRo4ciSeffBK9evXC9evX8d1332HlypWIjY3F2LFj8dlnnyExMRF79+7F7bffjsLCQvzyyy949tlncf/998PX1xcjR47E8uXLIZPJ0K5dO/zwww+NGivUqVMntGvXDjNnzsTly5fh4+ODb775xmS8k8E777yDAQMGoGfPnpg0aRKioqJw/vx5bNy4EYcOHTLZd+zYsXj44YcBAK+99lqjfo5ELk2qaVpEZH2GqeBZWVkm28eNGyc8PT1r7X/nnXeKW265xWRbRkaGmDBhgggICBBqtVrExMSYTHc2uHbtmnjiiSeEj4+P8PX1FU888YQ4ePBgrenRQgiRmpoqxo4dK0JCQoRKpRJhYWHivvvuE2vXrjXu09Cp4Ddu3DCWz8vLSyQkJIiTJ0+KiIgIk2nthjJOnTpVhIWFCbVaLVq3bi3GjRsnsrOzjfsUFRWJuXPniqioKKFSqURISIh4+OGHRWpqqnGfrKws8dBDDwkPDw/RokUL8X//93/i6NGjZqeCm/s5CyHE8ePHRXx8vPDy8hIBAQFi4sSJ4vDhw2Z/XkePHhUjRowQfn5+ws3NTURHR4t58+bVOmdpaalo0aKF8PX1FcXFxfX+3IiaE5kQNhxNSERENlNRUYFWrVph+PDh+Oijj6QuDpHD4JgbIiIntWHDBmRlZZkMUiYigC03REROZs+ePfjzzz/x2muvISAgwOTmhUTElhsiIqfz/vvvY/LkyQgKCsJnn30mdXGIHA5bboiIiMilsOWGiIiIXArDDREREbmUZncTP51OhytXrsDb27tJq/4SERGR/QghkJ+fj1atWtVav62mZhdurly5gvDwcKmLQURERBa4ePEiWrduXe8+zS7cGG4ff/HiRfj4+EhcGiIiImqIvLw8hIeHG6/j9Wl24cbQFeXj48NwQ0RE5GQaMqRE0gHFO3fuxPDhw9GqVSvIZDJs2LDhpsds374dPXv2hEajQfv27fHJJ5/YvJxERETkPCQNN4WFhYiNjcWKFSsatP+5c+cwbNgw3HXXXTh06BCmT5+Op59+Gj/99JONS0pERETOQtJuqSFDhmDIkCEN3n/lypWIiorC4sWLAQCdO3fGb7/9hn/9619ISEiwVTGJiIjIiTjVmJuUlBTEx8ebbEtISMD06dOt/l5arRbl5eVWP29zoFKpoFAopC4GERE1U04VbtLT0xEcHGyyLTg4GHl5eSguLoa7u3utY0pLS1FaWmr8Pi8vr973EEIgPT0dOTk5Vilzc+Xn54eQkBDeS4iIiOzOqcKNJZKSkvDqq682eH9DsAkKCoKHhwcvzo0khEBRUREyMzMBAKGhoRKXiIiImhunCjchISHIyMgw2ZaRkQEfHx+zrTYAMHv2bCQmJhq/N8yTN0er1RqDTcuWLa1X8GbG8FlkZmYiKCiIXVRERGRXThVu4uLisGnTJpNtW7ZsQVxcXJ3HaDQaaDSaBp3fMMbGw8PD8kISgKqfYXl5OcMNERHZlaRTwQsKCnDo0CEcOnQIgH6q96FDh5CWlgZA3+oyduxY4/7PPPMMzp49ixdffBEnT57Ee++9h6+++gozZsywarnYFdV0/BkSEZFUJA03+/fvR48ePdCjRw8AQGJiInr06IH58+cDAK5evWoMOgAQFRWFjRs3YsuWLYiNjcXixYvxn//8h9PAiYiIyEjSbqmBAwdCCFHn6+buPjxw4EAcPHjQhqWiyMhITJ8+3SZT7ImIiGzNqcbcUN0GDhyI7t27Y+nSpU0+1759++Dp6dn0QhEREUmA4aaZEEJAq9VCqbz5Rx4YGGiHEhGRgRACJeU6uKsVyC4oRUm5VuoiETWJWilHkLebZO/PcOMCxo8fjx07dmDHjh1YtmwZAODjjz/GhAkTsGnTJrz88ss4cuQIfv75Z4SHhyMxMRG///47CgsL0blzZyQlJZnc+blmt5RMJsO///1vbNy4ET/99BPCwsKwePFi/O1vf5OiukQuZ+6Go/jmwCU8NSAK721Plbo4RE3Ws40f1j3bX7L3Z7i5CSEEiiX6X5S7StGgWUfLli3D6dOn0bVrVyxcuBAAcOzYMQDArFmz8Pbbb6Nt27Zo0aIFLl68iKFDh+If//gHNBoNPvvsMwwfPhynTp1CmzZt6nyPV199FW+++SbeeustLF++HI899hguXLgAf39/61SWqBn79a8slFbo8OHOswAApVwGhZwzDsl5qRSSzldiuLmZ4nItusyXZtXx4wsT4KG++Ufk6+sLtVoNDw8PhISEAABOnjwJAFi4cCHuuece477+/v6IjY01fv/aa69h/fr1+O677zB16tQ632P8+PEYM2YMAGDRokV45513sHfvXtx7770W1Y2I9LQ6gas5JQCACp1+gsU7Y3pgaAzv7k1kKWmjFdlc7969Tb4vKCjAzJkz0blzZ/j5+cHLywsnTpwwmXJvTrdu3YzPPT094ePjY1xigYgsl5lfYgw1BmF+5u+4TkQNw5abm3BXKXB8oTT30XFXNf3OvjVnPc2cORNbtmzB22+/jfbt28Pd3R0PP/wwysrK6j2PSqUy+V4mk0Gn0zW5fETN3eUbxbW2tWK4IWoShpubkMlkDeoakpparYZWe/OxQbt27cL48eMxYsQIAPqWnPPnz9u4dERUl8s5puFGo5QjwEstUWmIXAO7pVxEZGQk9uzZg/PnzyM7O7vOVpUOHTpg3bp1OHToEA4fPoxHH32ULTBEErpUo+UmzM+dy5cQNRHDjYuYOXMmFAoFunTpgsDAwDrH0CxZsgQtWrRAv379MHz4cCQkJKBnz552Li0RGdRsuQlrwS4poqZy/P4WapCOHTsiJSXFZNv48eNr7RcZGYmtW7eabJsyZYrJ9zW7qcwtkZGTk2NROYnIVM0xNxxMTNR0DDdElXKKyjD+4324NbIF5g7r0ujjP919Hm//dKrWzBei+pRU6MfKKeQyaHWC4YbIChhuiCqt++MyDl3MwZ+XcjDx9rYI8mn4rcMrtDos3/oX8ksrbFhCclU+bko82LM1/vv7BfRt21Lq4hA5PYYbokrrD14GAOgE8N3hK3j69rYNPvbXM9nILihDS0811j3bD3IOCKVGaOmlhodaiRcSouGp4Z9loqbivyJqtjYfvYp3ks9g6ejukMuAI5dzja+9+dMpfLDzLNoGeOLTJ/vAzcw9h4QQeG71Ifx+9hoKK1tshse2QkRLrqhOlmGwIbIO/kuiZuuZz/8AALz6/THEtvYDAPSJ9MfpzHzkFJUjK78UWfmlOHwxx2xXwR9pN/D94SvG75VyGUbdGm6XshMRUd0YbqhZqj4DLDu/DN8e0oeUsf0icHv7QFzOKcbcDUdwMC2n1lRdg3V/6LuxhnQNwd/v7oAAL3WjxukQEZFtMNyQS/nu8BV8vf8i3h4Zi2AfN1wvLMPkzw8gK78UANC/fQAiWnrgx6PpxmNOZeQDALw1SsR3DoabSgFfDxXaB3rhYFoOPt19Hh/sOAuFXIZFD8agbaAnJn9+ALvOXAMAPNq3Dbq08rF/ZYmIyCyGG3IZWp3APzYeR0ZeKVbtOofZQzrjy71p2HPuunGfs9mFkMv0g4Zriu8SbDK2xnAztcOXqsbivLv1DG7vEGAMNpEtPdCvXYCNakRERJbgHYrJZexOzUZGnr6F5tuDV6DVCeMMqGmDOuCOjoEAzAcbAIgJ8zX53tz9RrafysSqXecAAMNiQvHtlAFQyDkziojIkbDlhhze1/sv4vM9abXulCyTyfBon3CMurUNVmw7g7d+OmV8LT2vBPcu3YkzmQXQKOV46vYopKRew87TWXW+T+dQ066l6rfBV8plaBvoidMZBbhwrQgKuQyv3n8LfD1UNU9DREQSY7hxEQMHDkT37t2xdOlSq5xv/PjxyMnJwYYNG6xyPkuVlGux8IfjyC8xf3O8s5kF6BPVEm//XBVs4tq2RMrZa/grswAAMKxbKHzcVLgrOghhfu7ILS5H+yAvHLqYY3KuzqHeJt+39vMwPm8b6Ikn4iIxb8NRAMA9nYMR4KWxRhWJiMjKGG7IoW09mYn8kgqE+Lhh0YNdTV6bt+EYLucU4+9f/gEhADeVHOsm90e7IE/sO3cDZVotlHI5bo30BwColXKsn9IPZRU6+HuqcSWnGPFLdhrP5+ehNjl/iG/VzKcgbzc81qcNOgZ5oaRCh94RLWxYayIiagqGGxcwfvx47NixAzt27MCyZcsAAOfOnUNBQQFeeOEF/Prrr/D09MTgwYPxr3/9CwEB+gGwa9euxauvvoozZ87Aw8MDPXr0wLfffou33noLn376KQB91w8AbNu2DQMHDrSofHkl5Xh5/VFkF+jHw9zRMRB+7ip8V+0eMe4qBWYN6YQOwd7Q6QRe33gCJ9PzcC67EADwQI8w3N0p2OS8B3rcwIptqTh6OQ8AsGD4LcZZSwM6mB/kG+RdFVjaB3mb3cdArawakubtpoRcLuOt8YmInADDzc0IAZQXSfPeKg+gAbfxX7ZsGU6fPo2uXbti4cKF+kNVKvTp0wdPP/00/vWvf6G4uBgvvfQSHnnkEWzduhVXr17FmDFj8Oabb2LEiBHIz8/Hr7/+CiEEZs6ciRMnTiAvLw8ff/wxAMDf39/iaqzem2YSZHanXoNaIUeZVmeyn5tagRWP9sSu1GzjoF1Av6Dgw73Cap33oZ6tsXLHWWh1Al4aJYbGhDa6bM8ObIf3tqdiQv9Is693DfPB0ct5GN2nTaPPTURE0mC4uZnyImBRK2nee84VQH3zW/n7+vpCrVbDw8MDISEhAIDXX38dPXr0wKJFi4z7rVq1CuHh4Th9+jQKCgpQUVGBBx98EBEREQCAmJgY477u7u4oLS01nq8pDDe7G98vEgcv5uDwxRyUaXWICvDE9PgOuFZQhoU/HMeW4xnIKynH+sr94zsHY3hsKCJbepptZWkb6IX1z/bDuexC3NLKB77ujR/cOy2+AwZ0CECvOrqZ/vtkX6RmFaB3pOXhjoiI7IvhxkUdPnwY27Ztg5eXV63XUlNTMXjwYAwaNAgxMTFISEjA4MGD8fDDD6NFi6aPJSkoKUfGjSJcLyxD9rnrOJmeD7VCjhnxHbHlRAYOVw7kfbhXa9zfPQxCCHy5Nw1/ZRbgmwOXsPmY/gZ7kwe2Ra+I+kNFt9Z+6Fa5dIIlNEpFvfepaeGpRm9PBhsiImfCcHMzKg99C4pU722hgoICDB8+HP/85z9rvRYaGgqFQoEtW7Zg9+7d+Pnnn7F8+XLMnTsXe/bsQVRUlMXvK4TApZxilJZWoKhMi6TkYwCAuzsFwddDhXu7huDV74+htFyHB3rou5pkMhlG9AzDm5tP4a2fTqGoTIuIlh7o2YaDdomIqPEYbm5GJmtQ15DU1Go1tFqt8fuePXvim2++QWRkJJRK8x+zTCZD//790b9/f8yfPx8RERFYv349EhMTa52voYrKtCirqBpLU1qhP8eInvog46VRYt3kfiit0JncJO+B7vpwU1SmNX4va8B4IyIiopp4h2IXERkZiT179uD8+fPIzs7GlClTcP36dYwZMwb79u1DamoqfvrpJ0yYMAFarRZ79uzBokWLsH//fqSlpWHdunXIyspC586djef7888/cerUKWRnZ6O8vLze979WUIqL14twpXKRSW83FRSV2cTXXYWB0YHGfTsEe6NrjbsBt/Jzx21tq7p/DK06REREjcVw4yJmzpwJhUKBLl26IDAwEGVlZdi1axe0Wi0GDx6MmJgYTJ8+HX5+fpDL5fDx8cHOnTsxdOhQdOzYES+//DIWL16MIUOGAAAmTpyI6Oho9O7dG4GBgdi1a1ed711SrsXlnGLcKCpDcbm+5cXXXQl3jb7F6IHuraBRKuo83mBkr3AAwK2RLRAV4PitZURE5JhkouY97V1cXl4efH19kZubCx8f09vtl5SU4Ny5c4iKioKbm1sdZ6CaruYWIyu/FB5qJXzdlVAr5NDIdTh79izOFHsgPqY1PNQ37wEVQuDHo+no0cYPob6113UiIqLmq77rd00cc9OM5ZeUI6+OZQ0aI7dI32UV6KWGb+VdfktKSiCTyTD4lhC4NSDYAPoxQJbcq4aIiKg6hptmSqcTSLtWBK2VGu4Uchm8LbjPDBERkbUx3DRTeSXl0AoBlUKOFjXWVLKEt5sScs5uIiIiB8Bw48LKK3TIKymHn4caN4rK4OuuQl5JeeV2fXdUCw+1yQKRREREzo7hxgxXGWN9KacY+SXlyMwvRblWh6zKr9X5edimK8lVfoZEROR8GG6qUan0F/qioiK4uzv3bJ1yrQ4FJeXG59W/eqiV8FAr4K5WwE118ynaligq0i82aviZEhER2QvDTTUKhQJ+fn7IzMwEAHh4eDjVXXILyyogByCDDFdzS6Cr4w7DLX2UcFfLAOhQUlJi1TIIIVBUVITMzEz4+flBobBNeCIiIqoLw00NhlWwDQHHWVRodcjIK4VMpp9SrdXpu4XkMkAnqr6qFDKoi20/xsbPz88qK4oTERE1FsNNDTKZDKGhoQgKCrrpkgOO5NPd5/BZimkgG1m56vbGI1fxt+6t8NPRdPSNaomoEG+blkWlUrHFhoiIJMNwUweFQuEUF2ghBH4+noGkn8+abB8bF4Hp93YFAEwN0a+uPfEuP3sXj4iIyO64tpST2516Df/33wMAAI1SDsMQoRFceJKIiJopttw4uT8u3DA+X/xILErKdcgpKkP3cD/pCkVERCQhhhsHdzDtBi5cK0LXMF94uynx+9lrMNxCxk0lx6GLOQCAOUM74b5uraQrKBERkYNguHFgZzLz8eD7uyEE4OOmRLi/B45dyTO7b6eQ+ldIJSIiai445saBfX3gkrGVJq+kwhhs+rVriZ5t/Ez27RRq2xlQREREzoItNw5ICIEDF27ggx1na73m56HCF0/3RYVOoMPcH43bg7y5PhQRERHAlhuHtP1UFh5emQJA3x01pk8b42udQ3wgk8mgUsjRJ9IfAOChdvwp60RERPbCcOOAjl7ONT6fP/wWxLb2NX5fvfvp3Ud7YFi3UHw8/la7lo+IiMiRsVvKAV3OKQYAzIjviId7tcbhyhlRANA5tGrgcJCPG1Y82tPexSMiInJobLlxQIZw08pPP46mY7A35JU35+tk46UTiIiInB1bbhzQ5Rv6cBPWwh0A4K5W4PnB0bicU4yurXzrO5SIiKjZY7hxMEIIY8tNaz8P4/Ypd7WXqkhEREROhd1SDia7oAylFTrIZECIL6d3ExERNRbDjYMxtNoEe7tBreTHQ0RE1FiSXz1XrFiByMhIuLm5oW/fvti7d2+d+5aXl2PhwoVo164d3NzcEBsbi82bN9uxtLZXc7wNERERNY6k4WbNmjVITEzEggUL8McffyA2NhYJCQnIzMw0u//LL7+MDz74AMuXL8fx48fxzDPPYMSIETh48KCdS247l3OKAABhfgw3RERElpA03CxZsgQTJ07EhAkT0KVLF6xcuRIeHh5YtWqV2f3/+9//Ys6cORg6dCjatm2LyZMnY+jQoVi8eLGdS247bLkhIiJqGsnCTVlZGQ4cOID4+PiqwsjliI+PR0pKitljSktL4eZmOsjW3d0dv/32W53vU1pairy8PJOHIzOMuWHLDRERkWUkCzfZ2dnQarUIDg422R4cHIz09HSzxyQkJGDJkiX466+/oNPpsGXLFqxbtw5Xr16t832SkpLg6+trfISHh1u1HtZ2iS03RERETSL5gOLGWLZsGTp06IBOnTpBrVZj6tSpmDBhAuTyuqsxe/Zs5ObmGh8XL160Y4kbr+oeNww3RERElpAs3AQEBEChUCAjI8Nke0ZGBkJCQsweExgYiA0bNqCwsBAXLlzAyZMn4eXlhbZt29b5PhqNBj4+PiYPR5VXUo78kgoAbLkhIiKylGThRq1Wo1evXkhOTjZu0+l0SE5ORlxcXL3Hurm5ISwsDBUVFfjmm29w//3327q4dmEYTNzCQwUPNW8eTUREZAlJr6CJiYkYN24cevfujT59+mDp0qUoLCzEhAkTAABjx45FWFgYkpKSAAB79uzB5cuX0b17d1y+fBmvvPIKdDodXnzxRSmrYTWcKUVERNR0koabUaNGISsrC/Pnz0d6ejq6d++OzZs3GwcZp6WlmYynKSkpwcsvv4yzZ8/Cy8sLQ4cOxX//+1/4+flJVAPr4kwpIiKippMJIYTUhbCnvLw8+Pr6Ijc31+HG3yzadAIf7jyLJ/tHYf7wLlIXh4iIyGE05vrtVLOlXF1qZgEAIKKlx032JCIiorow3DiQk+n5AIDOoY7VokRERORMGG4cRG5RuXHMTXSIt8SlISIicl4MNw7iZLp+WYgwP3f4uqskLg0REZHzYrhxEFVdUmy1ISIiagqGGwdx4qq+5aZTCMfbEBERNQXDjQPQ6QR2nM4CAMSG+0lbGCIiIifHcOMAfj97DVdzS+DjpsQdHQOkLg4REZFTY7hxAOsOXgYADOvWChqlQuLSEBEROTeGG4kVl2nx45GrAIAHe4ZJXBoiIiLnx6Wn7eXqYeCrcUBZIXDXbODYBiD9CK7798GjWn+McN+LTkHJNz0NERER1Y/hxl5ObgRunNM//3k+UKaf+h12eTPmqgAIAPs+BO50jRXOiYiIpMJuKXspyKh6Xhlsaikvtk9ZiIiIXBjDjb0UZN18H5nM9uUgIiJycQw39lK95aZODDdERERNxXBjL4WZN9+HLTdERERNxnBjD0IABQ0JN/w4iIiImopXU3sozQMqSvTPg7vWsyNbboiIiJqK4cYeDIOJ1d5Ai8i692O3FBERUZMx3NiDYTCxVyCEZ1A9OzLcEBERNRXDjT1UDibWeQYh+aIwbhaewab7seWGiIioyRhu7KFyMPGVCm9su6wPMFrIIfOuEW7YckNERNRkDDf2UNktdaXCB9nCFwAgPAIApZvpfud/BT4aDJz+GVh1r379KVciBLD2KWDzHKlLQkRELoxrS9lBSV423ACcLVDjmIiATqaAsnVPoLTAdMdzO/Rf/zdS/zUtBbgl165ltam8y8DRtQBkwODXATmzNRERWR+vLnZw7PxVAEBqngyXRBBOP7oHeOS/gEIlccnszBjmBFBeJGlRiIjIdTHc2EFebg4AoAj6bqioqLaAUg0o1BKWSgJlheafExERWRHDjR0EulUAAAqFPtxolAr9C82t5aa80PxzIiIiK2K4sQOVthgAUAQN+kb5V73AlhsiIiKrY7ixA3VluAkPDsTiR2KrXmC4ISIisjqGGztQC324GdW/E1q38Kh6obl1S5mEm4K69yMiImoChhs7cNPpw427l4/pC8063LDlhoiIbIPhxsZ0OgF3lAIAPLx8TV9s1t1SnApORES2wXBjYwUlpfCQ6cONZ7NvuSkw/5yIiMiKGG5sLD8/z/jczaNmuGlAy422wsolklD1G/exW4qIiGyEyy/YWGGBPtzoIINc5W76YkPCzVdPAG3igP7PAfs/Bvb9R79Gky1ovIG75gC/LgaKrgN9JgK9xtXeL/ME8P10oDS/4eeWy4Gs01Xf/7oEuHIQeOg/+hasa6nAppnAgBlA1B1NrgoRUbNz5SCw6UVAVw7cNRc48Alw/VzjztH2TiCoC7DnA8DDH3jw30CtRZ4r7fsI2L/K/DUppCvw4IeNroK1MNzYWFG+fm2oYrjBU1Zj1e+GdEud2gSk/a4PN7vfAa6ftUEpq/l6PFB8Xf9811Lz4ebwauDi7017n9Jc4PgG4LZngTZ9gWPrgNStgJsvww0RkSUOfgFc2qt/vm5S1d/yxsg8Brj7Vx17ahPQe4L5fX/7F5B70fxras/Gv7cVMdzYWEmhvuWmVO6OWh91QwcUG8anGNZmGr4M8IuwSvmMjq0H/vjU9B9DQab5fQ3be44Dbhlx83NfPwtsTKzjXBmm56zrPYmIqH6Gv6dA1d/ykBjgntcadvxX4/T/8WzIdUCIqvd76CPAo6Xp624+tY+xI4YbGyst0oebMrlb7RcbGm60ZUBFWdU4lag7Af8oK5WwUt5lfbiprqxA/541E3hh5S97eB+g3V03P3dAB2BjHa8Zw02NkENERI1TmFV7W8sODfs7DQDeIfpwY3LOOv4ml+Tor00A0Ok+QGXmGichDii2sbJifWtLucKj9ouNmS1VVlC1HpPaywolq8Grjj5Vc2HDEETqOqYmz8C6XzP8YywwfGW4ISKySPWWG4OG/p0GAK+ghp0TqPqbrfF1uGADMNzYXHmxftBthblwI29EuCnMrnquNnOupqorgJj7n4Dhl9rcPwRzlBrAzc/8azVbbkpzgfKShp2XiIiqFJj5e+1Vz38ua+1rJgiZOydQ7T+5DbwO2BnDjY1pS/QtNzqVuZabRtzEz9g0KAOU7vXuapE6W25qpHadrirweDbil7rO81eeq3qIqqsZlIiIzCsrAsrMzGC1VcuN4e80w03zpK0cBCyUTeyWMvyCqT3106qtzTPA9PvATpXvWyNoFF8HhBaArPYx9anrH0BBhv4fZWletW11/E+BiIjMM4QNpRvg16Zqe6P+E1ptX8M1wFzrPVB1bWC4aZ5EqWGcjJlpcY1puTH8Itlqep1CZTraPbir6fsay1EZsjz8GxfO6ur2Ksis3VJT1/8UiIjIvOphwyukantjwkf1IBQSo/9qmFhS6/0yah/jQBhubEyp1d+VV+fo4Qao+iVVugEt2+mf1woehn9AjWjqBOqeFliYWTtAsVuKiKhxDH9HPYNMA01jwk31v+stogDDcAqzE0saOfbSzhhubEyl1a8IrlOZCzeNGVBc+ctl7jzWYvgl9ar2j6NWy42FTZF1zfCqKNHfndjcexARUcNUn8Va/e9zfbNVa6oZiuq6DtR8PwfEcGNjal1ly43SCVpuDL/InkFVrTh1tao0timyvnJnHDX9nuGGiKhxDGNjvAKr/j67N3L4QM1wYziPudZ0Bx9QzJv42Zhaq5/WLGquKwU0MtxUG1BsK4YE7hVc9Tz9CPBRQtU+hlttN7rlpp5yH/qf/qtMDgidfimG9CONO//NyGRAt1H69bDyrwIJi/TbGir9CLDzLeDuefqbEhIR2UrKe8Dxbxt3zI3z+q/VW24a26riEQBABkCYnmfLfGD3u6b7Zp6sfA+Gm2bJXVc5FVztXfvFRs2WskPLTVDnyq+d9GNuFGqgotj8OlKGfRuqw2D9PxCNb9UdMCNvB87/WnWr707DgBPfA0XX9A9ryzyhHxynqwD6TGrcXZ4/Hqqf0XXlIDDdysGLiMhACOCXVwBtqWXHB3YCvEP1z4M6Ne5YhRIIjNYPFfBvp19A8+QP+iV0zK1rqHQDWkRaVk4bY7ixMV/dDQCA1t1Mv6e5lhvPQGDMamDvh8Cfa6q22yPcxI4BAqKB0G76G+/936/Atb9q7+fmC0T0b9y5gzoDk3frR/FXFAMVpfqp5Od36aeWq730YefKH9afLVVWBKyfpL9duEFBRuPCjWGqek6aVYtGRGSi+EZVsBn5KSBXNPxYd3+gTZy+VXriNqBl+8a//9jv9H8rvQKBO2YC4X31f7PNCYgG3Fs0/j3sgOHGxvy0leHGw1y4MdNyo3QDWvcGDn9pul1o9V9tGW7kCiD81qrvgzo1PvnXJ/iW2ts6DTX9PryP9d7PQKcDNkyu+hkCHNdDRI7JMHbGzRe45QHLzxPW07LjvIP1D0D/n9wO8ZaXQUIcUGxLOh18hb4LRmduxLq5cGPYpqxjrQ6Jl5F3SnJ57X5h3kuHiByRg89CchYMN7ZUkgMVKgAAOg8zd/M11y0lr2xMU2rMn9MWi2Y2BzXDZV133SQiklKBhTNSyQTDjS1V/pLmCE8o1WZaYszOlqqcwVNXy425Naro5mr+L4gtN0TkiBx8WQNnwXBjS5UX0CzhB4W59aDMdUsZpifXNYiM3VKWqdUtxZYbInJADn7/GGfBcGNLlV0f2cIXSrmZe6qYa7mRVX4kOm3t1wB2S1mKY26IyBmw5cYqJA83K1asQGRkJNzc3NC3b1/s3bu33v2XLl2K6OhouLu7Izw8HDNmzEBJSYmdSttIhpYb+EKlMNdyU0+3lK7C/DnZcmOZmv3XXL+KiBwRx9xYhaThZs2aNUhMTMSCBQvwxx9/IDY2FgkJCcjMNH/h+d///odZs2ZhwYIFOHHiBD766COsWbMGc+bMsXPJG6jyl1TfLWWm5UauqGqpMZAx3NhErZabTP3NsoiIHAlnS1mFpOFmyZIlmDhxIiZMmIAuXbpg5cqV8PDwwKpVq8zuv3v3bvTv3x+PPvooIiMjMXjwYIwZM+amrT2SqQw32cIXKkUdt/qv1XrDcGMTNcNNRYl+KYaGklUbA8VQRES2Un2NKLKYZDfxKysrw4EDBzB79mzjNrlcjvj4eKSkpJg9pl+/fvj888+xd+9e9OnTB2fPnsWmTZvwxBNP1Pk+paWlKC2tuo11Xl6e9SpxM9W6pZTmuqUAQK4CUK1bzZCB6hxzw3BjEZP/BVWunfLlGEBVx6w0QH9nzjtf1D+XKwFt5WeybhLQ43Gg7Z22Ki0RWeLUj8D+Vfo16pwVW26sQrJwk52dDa1Wi+Bg0w8wODgYJ0+eNHvMo48+iuzsbAwYMABCCFRUVOCZZ56pt1sqKSkJr776qlXL3mCVt/u/IbzMDygGAJ9WwLUz1e6eW7lf+3gg5V39RVXpDpTl65/zF94yPmH6afQqd8CvjX6NqAu/1X/MmV+AnmMB7xB9F6LhIzrylX7xTYYbIsey9XUg46jUpWg6N7/a9+aiRnGq5Re2b9+ORYsW4b333kPfvn1x5swZTJs2Da+99hrmzZtn9pjZs2cjMTHR+H1eXh7Cw8PtUl6hq4AMgBaKusPN42uBwmzg33fpvzeMuWl3FzDhR6BlB30z5dXD+vWZPPztUnaXo/ECntqivzmi2hM4t7P+7qWfZuvXeMm/qg832nLT1/PTbVteImq8/Kv6r4MWVC0e6YzCejZuYWWqRbJwExAQAIVCgYwM0ym5GRkZCAkJMXvMvHnz8MQTT+Dpp58GAMTExKCwsBCTJk3C3LlzITdzLxmNRgONpo67/dqaTt80qoOs7m4pvzb6h0H1AcYR/fRfvQKB4C42KmQzEtK16nns6Pr3/f09fbgpyNJ/jroa4YazrYgci7YcKLquf95zrH5hXmq2JBtQrFar0atXLyQnJxu36XQ6JCcnIy4uzuwxRUVFtQKMQqEf6CkccJCnqOz31UJed8tNLQ3dj2zKMAC5IKNqhd7qSnKBcge9BQFRc1SYDUDoB/+7s4W7uZO0WyoxMRHjxo1D79690adPHyxduhSFhYWYMGECAGDs2LEICwtDUlISAGD48OFYsmQJevToYeyWmjdvHoYPH24MOY5EVA4K1kEOZV2zpWqSMdw4BMPYpsJM/cwqcwqzAD/7dHES0U0YWlM9A/WL5VKzJmm4GTVqFLKysjB//nykp6eje/fu2Lx5s3GQcVpamklLzcsvvwyZTIaXX34Zly9fRmBgIIYPH45//OMfUlWhfpUtNwIyKBv8j43hxiEYBvMVZAIVZlpuDK8x3BA5BuOdfTkQlxxgQPHUqVMxdepUs69t377d5HulUokFCxZgwYIFdihZ0wnjmBu5+Zv4mVPzpn4kDUPLTUE9LTdcwoHIcXAKNVXDK6ktVU7vlte1CKY57JZyDIYxN4VZdbfccFAxkePgsgVUDcONLVW23Mga1RrDcOMQqg8orrPlhuGGyGFwwUmqhuHGhgyzpdCYwc5suXEMhv/93WzMDRE5hkKGG6rCcGNLxm4pttw4HcMfyJIcoLSOJTs45obIcRhbbjjmhhxgQLFLM7TccMyN83FvoV/3S1cOrBlrfp8Lu4GvxtV/Hpkc6PkEkH0GUCgB33Dgwi4gZiTwx2dA76f0a+HEjgZObQJCuukX9CzMAvo/Z/16kXnHNgBZp/RriRn+DZbkAduTgK4PA6nJQMYx/ZIbvm30S3fEjAR2vVN3tyXZ19U/9V+5bAGB4ca2KsONoiFjbnxaA3mXgM7DbVwoahCZDGjZDsg6CZQXmr6m8dG35hRlA8c33Pxcl/YDuWn6oOPdSv85H10H5FzQL/SXc0EfbHIuAF4h+jsja0uBrg8BvmE2qR7VsDERKLoGdPmbfpkTADjxnf5O1Sc36j8bw7aanyE5EBngHyV1IcgBMNzYkmFAcUPG3EzaDlzaC3S817ZlooYb9QXwbq+q78P7Av3+DkQOAC7uu/mFrSAT2PmmPtgA+rCbd0n/3HBsza8F1dasyk9nuLGHilJ9sAGAvCtV4Savcp2i6p+zuc+w+2NAqx72KSvVL6CD6XI21Gwx3NhSZctNg6aCewUCnYbZuEDUKAHtgV4TgAMf67/X+FS1rHUcfPPjC7P14cZSHNNjH9UHhps8b+DPP+ZhoN3d1i0TETUJBxTbkiX3uSHHUn3mhbKRC7C6++vXubEU76NjH9UDTWEdz+vD+6oQORyLws22bdusXQ6XJKtsuZEx3Dgvk3Dj1rhj5fKmDW7kVHP7KKyr5aaBP3/OziFyOBaFm3vvvRft2rXD66+/josXL1q7TK7D0C3lgIt6UgN5NiHcAE1b54bhxj6qdz81NtzI5IAHV6AmcjQWhZvLly9j6tSpWLt2Ldq2bYuEhAR89dVXKCsrs3b5nJtxzA17/5xW9f+VN7ZbqubxjcUxN/ZRkFXteR1BBwBamJmF4xnYuFs9EJFdWHTVDQgIwIwZM3Do0CHs2bMHHTt2xLPPPotWrVrhueeew+HDh61dTqcka8yAYnJM1VteLAk3TRmPUZh1832o6aoHGsPPvKwIKMs33S+ka+1jOd6GyCE1uUmhZ8+emD17NqZOnYqCggKsWrUKvXr1wu23345jx45Zo4xOjN1STq/6xUtb3vjjm3IreLbc2IdJa03lc3ODiYNjam/jrf6JHJLF4aa8vBxr167F0KFDERERgZ9++gnvvvsuMjIycObMGURERGDkyJHWLKvTYcuNC9B4VT2vaxmG+jQp3LDlxi6qt5AVXdeHWHM/e3MtNww3RA7Jovvc/P3vf8eXX34JIQSeeOIJvPnmm+jateofvqenJ95++220atXKagV1Rgw3LqYkt/HHNGXMTVm+vntE7WH5OejmTFrIhP7+RDVbzWRyILBT7WMZbogckkXh5vjx41i+fDkefPBBaDTmxyEEBAQ07ynjQkAGAYDdUi6jxIKWm6auc/PtFIYbW8u9bPr9ppn6FpzqPAIA79Dax3LMDZFDsijcJCcn3/zESiXuvPNOS07vGgyLZgJQKDhbyql5twLyrwDtBzX+2BaR+q9+bYDyEn0XSFhP4PIBoHUf/ZIbhq+h3fWLM6rc9RfS7FPAsXXWrAnVRaEBAjsC6UeAkz9UbTd8Nv5R+pDpFayfRRXWC7i8n+sYETkoi8JNUlISgoOD8eSTT5psX7VqFbKysvDSSy9ZpXBOrVq4kcu5yoVTm7gVOLcDuGVE449tEQGMWQ34tAJ0Wn2XR1An4EKKfgmHk5uA6CHAmWSgdS/gxgVA7QmovYC/fgKEsH59qLbWvfUh9uQPVf92Ve5AzCPA2W364AnoP8vCbP36Uxd2Ax0SJCsyEdVNJkTj/3pGRkbif//7H/r162eyfc+ePRg9ejTOnTtntQJaW15eHnx9fZGbmwsfHx/bvVFFKfC6vsl6dvQmJI3pb7v3IiIicnGNuX5b1F+Snp6O0NDa/c+BgYG4evWqJad0PTqt8amCN/EjIiKyG4uuuuHh4di1a1et7bt27Wr2M6SMqndLKVUSFoSIiKh5sWgwyMSJEzF9+nSUl5fj7rvvBqAfZPziiy/i+eeft2oBnZaoarlRsuWGiIjIbiwKNy+88AKuXbuGZ5991rielJubG1566SXMnj3bqgV0WtVbbhQcUExERGQvFl11ZTIZ/vnPf2LevHk4ceIE3N3d0aFDhzrvedMsVRunreB9boiIiOymSU0KXl5euPXWW61VFtdSbUCxkve5ISIishuLw83+/fvx1VdfIS0tzdg1ZbBuHW88ZuiW0gkZW26IiIjsyKImhdWrV6Nfv344ceIE1q9fj/Lychw7dgxbt26Fr6+vtcvonCrDjRZyqOQyiQtDRETUfFgUbhYtWoR//etf+P7776FWq7Fs2TKcPHkSjzzyCNq0aWPtMjqnytlSOsigUDDcEBER2YtF4SY1NRXDhg0DAKjVahQWFkImk2HGjBn48MMPrVpAp1XZciMgg4pTwYmIiOzGoqtuixYtkJ+fDwAICwvD0aNHAQA5OTkoKiqyXumcWbVuKSVbboiIiOzGogHFd9xxB7Zs2YKYmBiMHDkS06ZNw9atW7FlyxYMGmTBysmuSGfolpJDyTE3REREdmNRuHn33XdRUlICAJg7dy5UKhV2796Nhx56CC+//LJVC+i0Ku9zo4OMU8GJiIjsqNHhpqKiAj/88AMSEhIAAHK5HLNmzbJ6wZyeYSo4W26IiIjsqtFNCkqlEs8884yx5YbqUG22FMfcEBER2Y9F/SV9+vTBoUOHrFwUF2PScsNuKSIiInuxaMzNs88+i8TERFy8eBG9evWCp6enyevdunWzSuGcmq6q5UbFlhsiIiK7sSjcjB49GgDw3HPPGbfJZDIIISCTyaDVaus6tPmo1nKjYMsNERGR3VgUbs6dO2ftcrie6ve54YBiIiIiu7Eo3ERERFi7HK7HcIdiIYOM2YaIiMhuLAo3n332Wb2vjx071qLCuBRjt5QMcqYbIiIiu7Eo3EybNs3k+/LychQVFUGtVsPDw4PhBjDplmK4ISIish+LRrreuHHD5FFQUIBTp05hwIAB+PLLL61dRudUOVtKQAaOJyYiIrIfq112O3TogDfeeKNWq06zVW22FFtuiIiI7MeqbQpKpRJXrlyx5imdF7uliIiIJGHRmJvvvvvO5HshBK5evYp3330X/fv3t0rBnJ6o6pbiuplERET2Y1G4eeCBB0y+l8lkCAwMxN13343Fixdbo1zOr1rLjYwtN0RERHZjUbjR6XTWLofrEQIAp4ITERHZGztMbKXa2lK8QTEREZH9WBRuHnroIfzzn/+stf3NN9/EyJEjm1wol8DZUkRERJKwKNzs3LkTQ4cOrbV9yJAh2LlzZ5ML5RIYboiIiCRhUbgpKCiAWq2utV2lUiEvL6/JhXIJolq3FDv/iIiI7Maiy25MTAzWrFlTa/vq1avRpUuXJhfKJbDlhoiISBIWzZaaN28eHnzwQaSmpuLuu+8GACQnJ+PLL7/E119/bdUCOi3DgGLB2VJERET2ZFG4GT58ODZs2IBFixZh7dq1cHd3R7du3fDLL7/gzjvvtHYZnZPJVHCJy0JERNSMWDwaZNiwYdi1axcKCwuRnZ2NrVu3WhxsVqxYgcjISLi5uaFv377Yu3dvnfsOHDgQMpms1mPYsGGWVsU22C1FREQkCYvCzb59+7Bnz55a2/fs2YP9+/c36lxr1qxBYmIiFixYgD/++AOxsbFISEhAZmam2f3XrVuHq1evGh9Hjx6FQqFwvCnoxgHFDDdERET2ZFG4mTJlCi5evFhr++XLlzFlypRGnWvJkiWYOHEiJkyYgC5dumDlypXw8PDAqlWrzO7v7++PkJAQ42PLli3w8PBwwHBjaLnhbCkiIiJ7suiye/z4cfTs2bPW9h49euD48eMNPk9ZWRkOHDiA+Pj4qgLJ5YiPj0dKSkqDzvHRRx9h9OjR8PT0bPD72gVXBSciIpKEReFGo9EgIyOj1varV69CqWz4GOXs7GxotVoEBwebbA8ODkZ6evpNj9+7dy+OHj2Kp59+us59SktLkZeXZ/KwC13VquAMN0RERPZjUbgZPHgwZs+ejdzcXOO2nJwczJkzB/fcc4/VCnczH330EWJiYtCnT58690lKSoKvr6/xER4ebp/CVW+5YbcUERGR3Vh02X377bdx8eJFRERE4K677sJdd92FqKgopKenY/HixQ0+T0BAABQKRa1WoIyMDISEhNR7bGFhIVavXo2nnnqq3v0MIczwMDdWyCaqj7lhyw0REZHdWBRuwsLC8Oeff+LNN99Ely5d0KtXLyxbtgxHjhxpVMuIWq1Gr169kJycbNym0+mQnJyMuLi4eo/9+uuvUVpaiscff7ze/TQaDXx8fEwe9iCM3VIcc0NERGRPFt3EDwA8PT0xYMAAtGnTBmVlZQCAH3/8EQDwt7/9rcHnSUxMxLhx49C7d2/06dMHS5cuRWFhISZMmAAAGDt2LMLCwpCUlGRy3EcffYQHHngALVu2tLQKNqXT6aCAYUCx1KUhIiJqPiwKN2fPnsWIESNw5MgRyGQyCCEgq9Y6odVqG3yuUaNGISsrC/Pnz0d6ejq6d++OzZs3GwcZp6WlQV5j0MqpU6fw22+/4eeff7ak+HYhTKaCM90QERHZi0XhZtq0aYiKikJycjKioqKwZ88eXL9+Hc8//zzefvvtRp9v6tSpmDp1qtnXtm/fXmtbdHQ0ROXyBo5K6CoAcMwNERGRvVkUblJSUrB161YEBARALpdDoVBgwIABSEpKwnPPPYeDBw9au5xOR+gqW24Eu6WIiIjsyaIBxVqtFt7e3gD0M56uXLkCAIiIiMCpU6esVzonZhhQzOUXiIiI7MuilpuuXbvi8OHDiIqKQt++ffHmm29CrVbjww8/RNu2ba1dRqckOBWciIhIEhaFm5dffhmFhYUAgIULF+K+++7D7bffjpYtW2LNmjVWLaDT0lVfFVzishARETUjFoWbhIQE4/P27dvj5MmTuH79Olq0aGEya6o5q+qWYssNERGRPVl8n5ua/P39rXUql1A93DDbEBER2Q9XPbKRqjE3crZmERER2RHDja1UttxAxh8xERGRPfHKayO6agOKiYiIyH545bWVym4pwZYbIiIiu+KV11YMq4Iz3BAREdkVr7w2YhhQLPgjJiIisiteeW3EsLaU4EwpIiIiu2K4sREhKmdL8UdMRERkV7zy2ophtpRMIXFBiIiImheGG1sxtNywW4qIiMiuGG5sRPA+N0RERJLglddWKmdL8Q7FRERE9sUrr61UdktxKjgREZF98cprI1VTwfkjJiIisideeW2Fyy8QERFJgldeWxFcFZyIiEgKvPLaCpdfICIikgSvvDbCMTdERETS4JXXViq7pWQMN0RERHbFK6+tCKH/wnBDRERkV7zy2oqu8j43DDdERER2xSuvrfAOxURERJLglddWjPe54argRERE9sRwYyu8zw0REZEkeOW1FWPLjUzighARETUvDDe2Yhxzw24pIiIie2K4sREZBxQTERFJgldeWzGEG7BbioiIyJ4YbmyFs6WIiIgkwXBjIzLD8gty/oiJiIjsiVdeW2HLDRERkSQYbmylcm0pDigmIiKyL155bcV4Ez8OKCYiIrInhhsbMU4Fl7NbioiIyJ4YbmyF3VJERESS4JXXRmRcW4qIiEgSvPLaCpdfICIikgTDjY3IUNktxfvcEBER2RWvvDZivIkfu6WIiIjsildeW2G3FBERkSQYbmyEq4ITERFJg1deGzGEG3ZLERER2RevvDYiExUAAJ1cKXFJiIiImheGGxuRV4YbIVdJXBIiIqLmheHGRhS6cgCATqGWuCRERETNC8ONjciFPtyw5YaIiMi+GG5sQaeDovI+Nww3RERE9sVwYwuVXVIAww0REZG9MdzYgrbM+FQoGG6IiIjsieHGFrRsuSEiIpKK5OFmxYoViIyMhJubG/r27Yu9e/fWu39OTg6mTJmC0NBQaDQadOzYEZs2bbJTaRuosuVGK2SQybn8AhERkT1Jeoe5NWvWIDExEStXrkTfvn2xdOlSJCQk4NSpUwgKCqq1f1lZGe655x4EBQVh7dq1CAsLw4ULF+Dn52f/wtenMtyUQwm5TCZxYYiIiJoXScPNkiVLMHHiREyYMAEAsHLlSmzcuBGrVq3CrFmzau2/atUqXL9+Hbt374ZKpe/uiYyMtGeRG6ayW6oMSsjlDDdERET2JFm3VFlZGQ4cOID4+PiqwsjliI+PR0pKitljvvvuO8TFxWHKlCkIDg5G165dsWjRImi12jrfp7S0FHl5eSYPm6sMN/qWG9u/HREREVWRLNxkZ2dDq9UiODjYZHtwcDDS09PNHnP27FmsXbsWWq0WmzZtwrx587B48WK8/vrrdb5PUlISfH19jY/w8HCr1sMsdksRERFJRvIBxY2h0+kQFBSEDz/8EL169cKoUaMwd+5crFy5ss5jZs+ejdzcXOPj4sWLti+ooeVGKCFjuCEiIrIrycbcBAQEQKFQICMjw2R7RkYGQkJCzB4TGhoKlUoFhaJqBlLnzp2Rnp6OsrIyqNW113HSaDTQaDTWLfzNGFtuFFAw3BAREdmVZC03arUavXr1QnJysnGbTqdDcnIy4uLizB7Tv39/nDlzBjqdzrjt9OnTCA0NNRtsJGPSLSVxWYiIiJoZSbulEhMT8e9//xuffvopTpw4gcmTJ6OwsNA4e2rs2LGYPXu2cf/Jkyfj+vXrmDZtGk6fPo2NGzdi0aJFmDJlilRVMK/6gGKmGyIiIruSdCr4qFGjkJWVhfnz5yM9PR3du3fH5s2bjYOM09LSIJdX5a/w8HD89NNPmDFjBrp164awsDBMmzYNL730klRVMI8DiomIiCQjE0IIqQthT3l5efD19UVubi58fHxs8ybHNgBfj8MeXSccGvQ//N+d7WzzPkRERM1EY67fTjVbymnoKgAA5ULBlhsiIiI7Y7ixhWrdUsw2RERE9sVwYwuV4aYCSig4oJiIiMiuGG5swbi2FLuliIiI7I3hxhZ4nxsiIiLJMNzYgiHccPkFIiIiu2O4sYVqN/HjmBsiIiL7YrixhcqWmzJ2SxEREdkdw40tmEwFZ7ohIiKyJ4YbW6i+thTDDRERkV0x3NiCMdwooOBPmIiIyK546bWFarOl2HJDRERkXww3tlCtW4pjboiIiOyL4cYWqg0oVjDcEBER2RXDjS1wKjgREZFkGG5sgd1SREREkmG4sQXjgGIFW26IiIjsjOHGFqqPuWG6ISIisiuGG1vgTfyIiIgkw3BjC7qqm/gx2xAREdkXw40tVOuWYssNERGRfTHc2EK1bimOuSEiIrIvhhtbMNznRijZLUVERGRnDDe2wAHFREREkmG4sQVOBSciIpIMw40tGMMNb+JHRERkbww3tsDlF4iIiCTDcGMLxuUXOOaGiIjI3pRSF8BlXNwHfHRP5TcCQOWYG4YbIiIiu2K4sSphfPaXLgzX4c2p4ERERHbGcGMtobG4OvEIhi//DQBwA15QqVQI83OXuGBERETNC8ONtSjVKFb7Ixu+8FQrsGFSHMJauKOFp1rqkhERETUrDDdWVKbVAQDc1QrEtPaVuDRERETNE2dLWVF5hX7MjUrBHysREZFUeBW2ojKtFgCgVvLHSkREJBVeha2orLLlRs2WGyIiIsnwKmxFhjE37JYiIiKSDq/CVlRWoQ837JYiIiKSDq/CVlSuZbghIiKSGq/CVmRsuWG3FBERkWR4FbYidksRERFJj1dhKzIMKGbLDRERkXR4FbYiQ8uNii03REREkuFV2IrYckNERCQ9XoWtqNw45kYmcUmIiIiaL4YbK2LLDRERkfR4FbYizpYiIiKSHq/CVsTlF4iIiKTHq7AVseWGiIhIerwKWxGXXyAiIpIer8JWxOUXiIiIpMersBWVseWGiIhIcrwKW1FZhQDAlhsiIiIp8SpsRZwtRUREJD1eha2orEILgN1SREREUnKIq/CKFSsQGRkJNzc39O3bF3v37q1z308++QQymczk4ebmZsfS1q1cq++WYssNERGRdCS/Cq9ZswaJiYlYsGAB/vjjD8TGxiIhIQGZmZl1HuPj44OrV68aHxcuXLBjietmmC2lYcsNERGRZCS/Ci9ZsgQTJ07EhAkT0KVLF6xcuRIeHh5YtWpVncfIZDKEhIQYH8HBwXYscd14Ez8iIiLpSXoVLisrw4EDBxAfH2/cJpfLER8fj5SUlDqPKygoQEREBMLDw3H//ffj2LFjde5bWlqKvLw8k4etlHNAMRERkeQkvQpnZ2dDq9XWankJDg5Genq62WOio6OxatUqfPvtt/j888+h0+nQr18/XLp0yez+SUlJ8PX1NT7Cw8OtXg+DUrbcEBERSc7prsJxcXEYO3YsunfvjjvvvBPr1q1DYGAgPvjgA7P7z549G7m5ucbHxYsXbVY240382HJDREQkGaWUbx4QEACFQoGMjAyT7RkZGQgJCWnQOVQqFXr06IEzZ86YfV2j0UCj0TS5rA1RtbaUzC7vR0RERLVJ2sSgVqvRq1cvJCcnG7fpdDokJycjLi6uQefQarU4cuQIQkNDbVXMBqtaW0ohcUmIiIiaL0lbbgAgMTER48aNQ+/evdGnTx8sXboUhYWFmDBhAgBg7NixCAsLQ1JSEgBg4cKFuO2229C+fXvk5OTgrbfewoULF/D0009LWQ0AXBWciIjIEUgebkaNGoWsrCzMnz8f6enp6N69OzZv3mwcZJyWlga5vCos3LhxAxMnTkR6ejpatGiBXr16Yffu3ejSpYtUVQAA6HSi2k382C1FREQkFZkQQkhdCHvKy8uDr68vcnNz4ePjY7XzlpRr0WneZgDAkVcGw9tNZbVzExERNXeNuX6z/8RKDF1SAO9zQ0REJCVeha3EMJgY4FRwIiIiKfEqbCVlxrsTyyCXc8wNERGRVBhurKS8giuCExEROQJeia2kTKsFwGngREREUuOV2EqM60qx5YaIiEhSvBJbSdU9bvgjJSIikhKvxFai1Qm4qxTwUHPpBSIiIilJfodiV9ErogVOvHav1MUgIiJq9thyQ0RERC6F4YaIiIhcCsMNERERuRSGGyIiInIpDDdERETkUhhuiIiIyKUw3BAREZFLYbghIiIil8JwQ0RERC6F4YaIiIhcCsMNERERuRSGGyIiInIpDDdERETkUhhuiIiIyKUopS6AvQkhAAB5eXkSl4SIiIgaynDdNlzH69Pswk1+fj4AIDw8XOKSEBERUWPl5+fD19e33n1koiERyIXodDpcuXIF3t7ekMlkVj13Xl4ewsPDcfHiRfj4+Fj13FJz5boBrl0/1s15uXL9XLlugGvXT6q6CSGQn5+PVq1aQS6vf1RNs2u5kcvlaN26tU3fw8fHx+V+mQ1cuW6Aa9ePdXNerlw/V64b4Nr1k6JuN2uxMeCAYiIiInIpDDdERETkUhhurEij0WDBggXQaDRSF8XqXLlugGvXj3VzXq5cP1euG+Da9XOGujW7AcVERETk2thyQ0RERC6F4YaIiIhcCsMNERERuRSGGyIiInIpDDdWsmLFCkRGRsLNzQ19+/bF3r17pS6SRV555RXIZDKTR6dOnYyvl5SUYMqUKWjZsiW8vLzw0EMPISMjQ8IS123nzp0YPnw4WrVqBZlMhg0bNpi8LoTA/PnzERoaCnd3d8THx+Ovv/4y2ef69et47LHH4OPjAz8/Pzz11FMoKCiwYy3Mu1ndxo8fX+tzvPfee032cdS6JSUl4dZbb4W3tzeCgoLwwAMP4NSpUyb7NOT3MC0tDcOGDYOHhweCgoLwwgsvoKKiwp5VMash9Rs4cGCtz++ZZ54x2ccR6/f++++jW7duxpu7xcXF4ccffzS+7syfG3Dz+jnr52bOG2+8AZlMhunTpxu3OdXnJ6jJVq9eLdRqtVi1apU4duyYmDhxovDz8xMZGRlSF63RFixYIG655RZx9epV4yMrK8v4+jPPPCPCw8NFcnKy2L9/v7jttttEv379JCxx3TZt2iTmzp0r1q1bJwCI9evXm7z+xhtvCF9fX7FhwwZx+PBh8be//U1ERUWJ4uJi4z733nuviI2NFb///rv49ddfRfv27cWYMWPsXJPabla3cePGiXvvvdfkc7x+/brJPo5at4SEBPHxxx+Lo0ePikOHDomhQ4eKNm3aiIKCAuM+N/s9rKioEF27dhXx8fHi4MGDYtOmTSIgIEDMnj1biiqZaEj97rzzTjFx4kSTzy83N9f4uqPW77vvvhMbN24Up0+fFqdOnRJz5swRKpVKHD16VAjh3J+bEDevn7N+bjXt3btXREZGim7duolp06YZtzvT58dwYwV9+vQRU6ZMMX6v1WpFq1atRFJSkoSlssyCBQtEbGys2ddycnKESqUSX3/9tXHbiRMnBACRkpJipxJapmYA0Ol0IiQkRLz11lvGbTk5OUKj0Ygvv/xSCCHE8ePHBQCxb98+4z4//vijkMlk4vLly3Yr+83UFW7uv//+Oo9xlroJIURmZqYAIHbs2CGEaNjv4aZNm4RcLhfp6enGfd5//33h4+MjSktL7VuBm6hZPyH0F8nqF5WanKl+LVq0EP/5z39c7nMzMNRPCNf43PLz80WHDh3Eli1bTOrjbJ8fu6WaqKysDAcOHEB8fLxxm1wuR3x8PFJSUiQsmeX++usvtGrVCm3btsVjjz2GtLQ0AMCBAwdQXl5uUtdOnTqhTZs2TlfXc+fOIT093aQuvr6+6Nu3r7EuKSkp8PPzQ+/evY37xMfHQy6XY8+ePXYvc2Nt374dQUFBiI6OxuTJk3Ht2jXja85Ut9zcXACAv78/gIb9HqakpCAmJgbBwcHGfRISEpCXl4djx47ZsfQ3V7N+Bl988QUCAgLQtWtXzJ49G0VFRcbXnKF+Wq0Wq1evRmFhIeLi4lzuc6tZPwNn/9ymTJmCYcOGmXxOgPP9u2t2C2daW3Z2NrRarcmHCQDBwcE4efKkRKWyXN++ffHJJ58gOjoaV69exauvvorbb78dR48eRXp6OtRqNfz8/EyOCQ4ORnp6ujQFtpChvOY+N8Nr6enpCAoKMnldqVTC39/f4et777334sEHH0RUVBRSU1MxZ84cDBkyBCkpKVAoFE5TN51Oh+nTp6N///7o2rUrADTo9zA9Pd3sZ2t4zVGYqx8APProo4iIiECrVq3w559/4qWXXsKpU6ewbt06AI5dvyNHjiAuLg4lJSXw8vLC+vXr0aVLFxw6dMglPre66gc49+cGAKtXr8Yff/yBffv21XrN2f7dMdyQiSFDhhifd+vWDX379kVERAS++uoruLu7S1gyaozRo0cbn8fExKBbt25o164dtm/fjkGDBklYssaZMmUKjh49it9++03qothEXfWbNGmS8XlMTAxCQ0MxaNAgpKamol27dvYuZqNER0fj0KFDyM3Nxdq1azFu3Djs2LFD6mJZTV3169Kli1N/bhcvXsS0adOwZcsWuLm5SV2cJmO3VBMFBARAoVDUGjGekZGBkJAQiUplPX5+fujYsSPOnDmDkJAQlJWVIScnx2QfZ6yrobz1fW4hISHIzMw0eb2iogLXr193uvq2bdsWAQEBOHPmDADnqNvUqVPxww8/YNu2bWjdurVxe0N+D0NCQsx+tobXHEFd9TOnb9++AGDy+Tlq/dRqNdq3b49evXohKSkJsbGxWLZsmct8bnXVzxxn+twOHDiAzMxM9OzZE0qlEkqlEjt27MA777wDpVKJ4OBgp/r8GG6aSK1Wo1evXkhOTjZu0+l0SE5ONumHdVYFBQVITU1FaGgoevXqBZVKZVLXU6dOIS0tzenqGhUVhZCQEJO65OXlYc+ePca6xMXFIScnBwcOHDDus3XrVuh0OuMfLWdx6dIlXLt2DaGhoQAcu25CCEydOhXr16/H1q1bERUVZfJ6Q34P4+LicOTIEZMAt2XLFvj4+Bi7EKRys/qZc+jQIQAw+fwctX416XQ6lJaWOv3nVhdD/cxxps9t0KBBOHLkCA4dOmR89O7dG4899pjxuVN9fnYdvuyiVq9eLTQajfjkk0/E8ePHxaRJk4Sfn5/JiHFn8fzzz4vt27eLc+fOiV27don4+HgREBAgMjMzhRD6qYBt2rQRW7duFfv37xdxcXEiLi5O4lKbl5+fLw4ePCgOHjwoAIglS5aIgwcPigsXLggh9FPB/fz8xLfffiv+/PNPcf/995udCt6jRw+xZ88e8dtvv4kOHTo4xHTp+uqWn58vZs6cKVJSUsS5c+fEL7/8Inr27Ck6dOggSkpKjOdw1LpNnjxZ+Pr6iu3bt5tMqS0qKjLuc7PfQ8OU1MGDB4tDhw6JzZs3i8DAQIeYcnuz+p05c0YsXLhQ7N+/X5w7d058++23om3btuKOO+4wnsNR6zdr1iyxY8cOce7cOfHnn3+KWbNmCZlMJn7++WchhHN/bkLUXz9n/tzqUnP2lzN9fgw3VrJ8+XLRpk0boVarRZ8+fcTvv/8udZEsMmrUKBEaGirUarUICwsTo0aNEmfOnDG+XlxcLJ599lnRokUL4eHhIUaMGCGuXr0qYYnrtm3bNgGg1mPcuHFCCP108Hnz5ong4GCh0WjEoEGDxKlTp0zOce3aNTFmzBjh5eUlfHx8xIQJE0R+fr4EtTFVX92KiorE4MGDRWBgoFCpVCIiIkJMnDixVth21LqZqxcA8fHHHxv3acjv4fnz58WQIUOEu7u7CAgIEM8//7woLy+3c21qu1n90tLSxB133CH8/f2FRqMR7du3Fy+88ILJ/VKEcMz6PfnkkyIiIkKo1WoRGBgoBg0aZAw2Qjj35yZE/fVz5s+tLjXDjTN9fjIhhLBfOxERERGRbXHMDREREbkUhhsiIiJyKQw3RERE5FIYboiIiMilMNwQERGRS2G4ISIiIpfCcENEREQuheGGiJq97du3QyaT1Vo3h4icE8MNERERuRSGGyIiInIpDDdEJDmdToekpCRERUXB3d0dsbGxWLt2LYCqLqONGzeiW7ducHNzw2233YajR4+anOObb77BLbfcAo1Gg8jISCxevNjk9dLSUrz00ksIDw+HRqNB+/bt8dFHH5nsc+DAAfTu3RseHh7o168fTp06ZduKE5FNMNwQkeSSkpLw2WefYeXKlTh27BhmzJiBxx9/HDt27DDu88ILL2Dx4sXYt28fAgMDMXz4cJSXlwPQh5JHHnkEo0ePxpEjR/DKK69g3rx5+OSTT4zHjx07Fl9++SXeeecdnDhxAh988AG8vLxMyjF37lwsXrwY+/fvh1KpxJNPPmmX+hORdXHhTCKSVGlpKfz9/fHLL78gLi7OuP3pp59GUVERJk2ahLvuugurV6/GqFGjAADXr19H69at8cknn+CRRx7BY489hqysLPz888/G41988UVs3LgRx44dw+nTpxEdHY0tW7YgPj6+Vhm2b9+Ou+66C7/88gsGDRoEANi0aROGDRuG4uJiuLm52finQETWxJYbIpLUmTNnUFRUhHvuuQdeXl7Gx2effYbU1FTjftWDj7+/P6Kjo3HixAkAwIkTJ9C/f3+T8/bv3x9//fUXtFotDh06BIVCgTvvvLPesnTr1s34PDQ0FACQmZnZ5DoSkX0ppS4AETVvBQUFAICNGzciLCzM5DWNRmMScCzl7u7eoP1UKpXxuUwmA6AfD0REzoUtN0QkqS5dukCj0SAtLQ3t27c3eYSHhxv3+/33343Pb9y4gdOnT6Nz584AgM6dO2PXrl0m5921axc6duwIhUKBmJgY6HQ6kzE8ROS62HJDRJLy9vbGzJkzMWPGDOh0OgwYMAC5ubnYtWsXfHx8EBERAQBYuHAhWrZsieDgYMydOxcBAQF44IEHAADPP/88br31Vrz22msYNWoUUlJS8O677+K9994DAERGRmLcuHF48skn8c477yA2NhYXLlxAZmYmHnnkEamqTkQ2wnBDRJJ77bXXEBgYiKSkJJw9exZ+fn7o2bMn5syZY+wWeuONNzBt2jT89ddf6N69O77//nuo1WoAQM+ePfHVV19h/vz5eO211xAaGoqFCxdi/Pjxxvd4//33MWfOHDz77LO4du0a2rRpgzlz5khRXSKyMc6WIiKHZpjJdOPGDfj5+UldHCJyAhxzQ0RERC6F4YaIiIhcCruliIiIyKWw5YaIiIhcCsMNERERuRSGGyIiInIpDDdERETkUhhuiIiIyKUw3BAREZFLYbghIiIil8JwQ0RERC6F4YaIiIhcyv8DvrJKKxtJirwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIrcCZ8P2t4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1346ee5a-d357-4b72-9b25-7c52ab709008"
      },
      "source": [
        "### 13. Plot code for the model loss. You can refer to the plot code for model accuracy above.\n",
        "scores=model.evaluate(x_test,y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1],scores[1]*100))\n",
        "print(\"loss: \", round(scores[0],2))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2528 - acc: 0.7419\n",
            "\n",
            "acc: 74.19%\n",
            "loss:  0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KTWzuJM12t4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46a17a4-ea4f-4314-851b-d01b238a0794"
      },
      "source": [
        "### 14. What is the purpose of evaluating the model on the test dataset?\n",
        "## to define how well the model performs its task\n",
        "#model.load_weights(model_loc+\"heart_disease_best_model.hdf5\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]))\n",
        "print(\"loss:\", round(scores[0],2))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2528 - acc: 0.7419\n",
            "\n",
            "acc: 74.19%\n",
            "loss: 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNYy0CRt2t4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b67082-1aa3-4cb0-b95f-21ac2b67b666"
      },
      "source": [
        "#Display detailed prediction\n",
        "pred = model.predict(x_test)\n",
        "y = np.round(pred).astype(\"int16\")\n",
        "idx = 0\n",
        "ps = 0\n",
        "fl = 0\n",
        "for x in pred:\n",
        "    if y_test[idx]==y[idx]:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\"Result: \\033[92mPass\")\n",
        "        ps = ps+1\n",
        "    else:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\" Result: \\033[91mFail\")\n",
        "        fl = fl+1\n",
        "    idx = idx + 1\n",
        "print(\"\\033[30mRight Prediction :\",ps, \"Wrong Prediction :\",fl)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 92ms/step\n",
            "\u001b[30mNo: 1 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 2 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 3 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 4 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 5 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 6 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 7 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 8 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 9 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 10 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 11 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 12 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 13 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 14 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 15 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 16 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 17 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 18 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 19 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 20 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 21 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 22 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 23 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 24 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 25 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 26 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 27 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 28 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 29 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 30 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 31 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mRight Prediction : 23 Wrong Prediction : 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHQBXNX5aYcn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "outputId": "eacd0e91-97dc-4a09-8ffa-d5e9d078b0ad"
      },
      "source": [
        "### 15. What is Confusion Matrix and why you need it? Explain TP, FP, FN, TN.\n",
        "##- a table that is used to define the performance of a classification algorithm\n",
        "## help to visualizes and summarizes the performance of a classification algorithm.\n",
        "#TP: True Positive (predict P when the case P)\n",
        "#FP: False Positive (predict P when the case N)\n",
        "#FN: False Negative (predict N when the case P)\n",
        "#TN: True Negative (predict N when the case N)\n",
        "\n",
        "### 16. Explain the classification report produce.\n",
        "y_pred = y\n",
        "y_true = y_test\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "#cm = confusion_matrix(y_true, y_pred, labels=labels.astype('int'))\n",
        "f, ax=plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cm,annot=True,linewidths=1.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()\n",
        "print()\n",
        "print(classification_report(y_true, y_pred, labels=[0,1]))\n",
        "\n",
        "#Accuracy = represented as the ratio of correctly classified to the total number\n",
        "#Precision = represented as the ratio of correctly classified positive to the predicted positive\n",
        "#Recall = represented as the ratio of correctly classified positive to the real case positive\n",
        "#F1 score = states the equilibrium between the precision and the recall"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAHFCAYAAABxfbchAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAn5klEQVR4nO3de1hVddr/8c8GdKuo2xMimIeSytJCUjOtJh1JI/NQk5TjFGqHmfKno0wHeZ5HpbFC7eTPNEunCcmmbCblsXrSCylTJ8dDho/1S1MjTTyUpSCYW2Cv3x8VM3vAw5YFC77r/epa18U67LXuPRfD7X2v7/ouj2VZlgAAMEiY0wEAAGA3khsAwDgkNwCAcUhuAADjkNwAAMYhuQEAjENyAwAYh+QGADAOyQ0AYBySGwDAOCQ3AECtWbt2rYYOHarY2Fh5PB5lZ2cH7U9PT1fXrl0VGRmpli1bKjExURs3bgz5OiQ3AECtKSkpUXx8vObPn1/l/ksuuUTz5s3T9u3btX79enXu3FmDBg3St99+G9J1PEycDABwgsfj0fLlyzVixIjTHlNUVCSfz6fVq1dr4MCB53zuCBviAwC4mN/vl9/vD9rm9Xrl9Xqrdd5Tp05p4cKF8vl8io+PD+mzZiY3j8fpCADAXjY32UqPfGnbuTLmZemxxx4L2jZ9+nSlp6ef1/neeecd3XnnnTpx4oRiYmKUk5OjNm3ahHQOM9uSJDcAprE7uX2zy7ZzBXwdz6tyO11bsqSkRAcPHtSRI0e0aNEivf/++9q4caPatm17zjGZWbn9pHDMufdngVD4MnOD1iMaxDoUCUxXVnrA6RDOyo4W5L+KjIxUXFyc4uLidM011+jiiy/Wyy+/rLS0tHM+h9HJDQBwGlbA6QjOWSAQqFQZng3JDQDcKOBMcisuLtbu3bsr1vPz85WXl6dWrVqpdevWeuKJJzRs2DDFxMToyJEjmj9/vgoKCjRy5MiQrkNyAwDUmi1btmjAgAEV66mpqZKklJQUvfjii9qxY4cWL16sI0eOqHXr1urdu7fWrVunbt26hXQdkhsAuJDlUFuyf//+OtM4xmXLltlyHZIbALiRQ23J2sL0WwAA41C5AYAb1aPRkueD5AYAbhQodzqCGkVbEgBgHCo3AHAj2pIAAOMwWhIAgPqFyg0AXMiph7hrC8kNANyItiQAAPULlRsAuBFtSQCAcXiIGwCA+oXKDQDciLYkAMA4jJYEAKB+oXIDADeiLQkAMA5tSQAA6hcqNwBwIcsy+zk3khsAuJHh99xoSwIAjEPlBgBuZPiAEpIbALgRbUkAAOoXKjcAcCPD3wpAcgMAN6ItCQBA/ULlBgBuxGhJAIBxaEsCAFC/kNwAwI0CAfuWEKxdu1ZDhw5VbGysPB6PsrOzK/aVlpbq0Ucf1RVXXKHIyEjFxsbq7rvv1oEDB0L+eiQ3AHAjh5JbSUmJ4uPjNX/+/Er7Tpw4oa1bt2rq1KnaunWrli1bpp07d2rYsGEhfz3uuQEAqsXv98vv9wdt83q98nq9lY5NSkpSUlJSlefx+XzKyckJ2jZv3jxdffXV2rdvnzp27HjOMVG5AYALWVa5bUtGRoZ8Pl/QkpGRYUuchYWF8ng8atGiRUifo3IDADey8VGAtLQ0paamBm2rqmoL1cmTJ/Xoo49q1KhRat68eUifJbkBAKrldC3I6igtLVVycrIsy9KCBQtC/jzJDQDcqA4/5/ZzYtu7d6/ef//9kKs2ieQGAO5UR2co+Tmx7dq1Sx988IFat259XuchuQEAak1xcbF2795dsZ6fn6+8vDy1atVKMTExuv3227V161a98847Ki8v16FDhyRJrVq1UsOGDc/5OiQ3AHAjh9qSW7Zs0YABAyrWfx6IkpKSovT0dK1YsUKS1KNHj6DPffDBB+rfv/85X4fkBgBu5FBbsn///rIs67T7z7QvFDznBgAwDpUbALhRHR4taQeSGwC4UR0dLWkX2pIAAONQuQGAGxleuZHcAMCNDL/nRlsSAGAcKjcAcCPakgAA49CWBACgfqFyAwA3oi0JADAObUkAAOoXKjcAcCPakgAA4xie3GhLAgCMQ+UGAG5k00tB6yqSGwC4EW1JAADqFyo3AHAjwys3khsAuBEPcQMAUL9QuQGAG9GWBAAYx/BHAWhLAgCMQ+UGAG5EWxIAYBzDkxttSQCAcajcAMCNDH/OjeQGAC5kBRgtCQBAvULlBgBuxIASAIBxrIB9SwjWrl2roUOHKjY2Vh6PR9nZ2UH7ly1bpkGDBql169byeDzKy8s7r69HcgMA1JqSkhLFx8dr/vz5p91/3XXXadasWdW6Dm1JAHAjGweU+P1++f3+oG1er1der7fSsUlJSUpKSjrtue666y5J0ldffVWtmKjcAMCNAgHbloyMDPl8vqAlIyPD0a9H5QYAqJa0tDSlpqYGbauqaqtNJDcAcCMbR0uergXpJJIbALgRr7wBAKB+oXIDADdy6CHu4uJi7d69u2I9Pz9feXl5atWqlTp27Kjvv/9e+/bt04EDByRJO3fulCS1a9dO7dq1O+frULm5TPglV6jJ72eo2bNvyPfKakUk9Kt0jHdEipo9t1TNX3pXkQ/NVlh0ewcihckeeXi8yk4V6JmnH3M6FPcKWPYtIdiyZYsSEhKUkJAgSUpNTVVCQoKmTZsmSVqxYoUSEhI0ZMgQSdKdd96phIQEvfjiiyFdh8rNZTzeRir/+kudWrdSkRMq/2FpePMd8t54q078abYC3x5Uo9vGKjJ1po7/5ziprNSBiGGaXj3jdd+9v9G2//1/TocCB/Tv31/WGe73jRkzRmPGjKn2dajcXKZs+2b5l72isq1/r3K/98bbdPLt11T2yUcK7M/XiUWz5GnZWg2uuraWI4WJIiObKCtrnn73wCM6dvSY0+G4m0PTb9UWRyu3I0eO6M9//rM2bNigQ4cOSfqxr9qvXz+NGTNGUVFRTobnOp6oGIW1aK2yz7b+c+MPJSrf87nC4y5X6aY1jsUGMzw/90m99z+5yn1/nf4jbaLT4bib4a+8cSy5bd68WYMHD1aTJk2UmJioSy65RJJ0+PBhzZ07VzNnztSqVavUq1evM56nymlffloQmjBfS0mSVXQ0aHug6Jg8vlZOhASDJCcPU0JCd13Td4jTocAFHEtuEyZM0MiRI/Xiiy/K4/EE7bMsS7/73e80YcIEbdiw4YznycjI0GOPBd87mi4p3eZ4AZy/Cy6I1XPP/FE33Tyq0j9G4QzL8FfeOJbctm3bpszMzEqJTZI8Ho8mT55cMZrmTKqc9sXnsy1ONwkU/lixeZq3lFX4fcX2sOYtVP71HqfCggGuuuoKRUdHafPGlRXbIiIidP3112j8g2PUpOmFChj+x7bOoS1ZM9q1a6dNmzapa9euVe7ftGmToqOjz3qeujjtS31lfXtQgWPfKeLyBJ36OZk1aqLwLpfp1AdvOxsc6rX331+v+IRfBm3706JntXPnHj319HwSG2znWHJ76KGHdP/99+vjjz/WwIEDKxLZ4cOHlZubq0WLFunpp592KjxzeRsprO0/n1sLi4pRWIcuskqOy/r+G/lzlqnR0NEKHC5Q4MghNbp1jKyj36n0NKMrgXNRXFyizz7bGbTtRMkJfffd0UrbUUvq6ChHuziW3MaPH682bdroueee0wsvvKDy8nJJUnh4uHr27KnMzEwlJyc7FZ6xwjtfqqZTnqlYbzzqAUnSqfWr9MPLT+nU/yyVp2EjNR4zWZ4mTVX+xacqeXYKz7gBpjG8LemxzvQ0XS0pLS3VkSNHJElt2rRRgwYNqnfCn+7jFY4ZWN3QgCr5MnOD1iMaxDoUCUxXVvrjNFR2T3Rc8sfRtp0rctprtp3LLnVihpIGDRooJibG6TAAwD0Mv89ZJ5IbAKCWGd6WZPotAIBxqNwAwI0YLQkAMA5tSQAA6hcqNwBwIeaWBACYh7YkAAD1C5UbALiR4ZUbyQ0A3MjwRwFoSwIAjEPlBgBuRFsSAGAay/DkRlsSAGAcKjcAcCPDKzeSGwC4keEzlNCWBAAYh8oNANyItiQAwDiGJzfakgAA41C5AYALWRaVGwDANAHLviUEa9eu1dChQxUbGyuPx6Ps7Oyg/ZZladq0aYqJiVHjxo2VmJioXbt2hfz1SG4AgFpTUlKi+Ph4zZ8/v8r9s2fP1ty5c/Xiiy9q48aNioyM1ODBg3Xy5MmQrkNbEgDcyKEBJUlJSUpKSqpyn2VZmjNnjv7rv/5Lw4cPlyRlZWUpOjpa2dnZuvPOO8/5OlRuAOBCVsCybfH7/SoqKgpa/H5/yDHl5+fr0KFDSkxMrNjm8/nUp08fbdiwIaRzkdwAANWSkZEhn88XtGRkZIR8nkOHDkmSoqOjg7ZHR0dX7DtXtCUBwI1sbEumpaUpNTU1aJvX67Xt/OeD5AYAbmTj1JJer9eWZNauXTtJ0uHDhxUTE1Ox/fDhw+rRo0dI56ItCQCoEy688EK1a9dOubm5FduKioq0ceNG9e3bN6RzUbkBgAs59bLS4uJi7d69u2I9Pz9feXl5atWqlTp27KhJkybp8ccf18UXX6wLL7xQU6dOVWxsrEaMGBHSdUhuAOBGDiW3LVu2aMCAARXrP9+rS0lJUWZmph555BGVlJTo/vvv17Fjx3Tddddp5cqVatSoUUjX8VgmzsHi8UiSCscMdDgQmMqXmRu0HtEg1qFIYLqy0gM//mDzn+pjowac/aBz1OL1D2w7l12o3ADAjcx+VynJDQDcyKl7brWF0ZIAAONQuQGAG9GWBACYhrYkAAD1DJUbALgRbUkAgGksw5MbbUkAgHGo3ADAjQyv3EhuAOBCtCUBAKhnqNwAwI0Mr9xIbgDgQrQlAQCoZ6jcAMCFTK/cSG4A4EKmJzfakgAA41C5AYAbWR6nI6hRJDcAcCHakgAA1DNUbgDgQlaAtiQAwDC0JQEAqGeo3ADAhSxGSwIATENbEgCAeobKDQBcyPTRklRuAADjULkBgAtZltMR1CySGwC4EG1JAADqGZIbALiQFfDYtoTq+PHjmjRpkjp16qTGjRurX79+2rx5s63fj+QGAC5kWfYtobr33nuVk5OjV199Vdu3b9egQYOUmJiogoIC274fyQ0AUGt++OEHvfXWW5o9e7Z+8YtfKC4uTunp6YqLi9OCBQtsuw4DSgDAhewcUOL3++X3+4O2eb1eeb3eSseWlZWpvLxcjRo1CtreuHFjrV+/3raYqNwAwIUsy2PbkpGRIZ/PF7RkZGRUed1mzZqpb9++mjFjhg4cOKDy8nItWbJEGzZs0MGDB237fiQ3AEC1pKWlqbCwMGhJS0s77fGvvvqqLMtS+/bt5fV6NXfuXI0aNUphYfalpGq1JU+ePFmptAQA1H12Tpx8uhbk6XTp0kUffvihSkpKVFRUpJiYGN1xxx266KKLbIsp5DQZCAQ0Y8YMtW/fXk2bNtWXX34pSZo6dapefvll2wIDANScgOWxbTlfkZGRiomJ0dGjR7Vq1SoNHz7ctu8XcnJ7/PHHlZmZqdmzZ6thw4YV27t3764//elPtgUGADDTqlWrtHLlSuXn5ysnJ0cDBgxQ165dNXbsWNuuEXJyy8rK0sKFCzV69GiFh4dXbI+Pj9eOHTtsCwwAUHPsHFASqsLCQo0fP15du3bV3Xffreuuu06rVq1SgwYNbPt+Id9zKygoUFxcXKXtgUBApaWltgQFAKhZTs4tmZycrOTk5Bq9RsiV2+WXX65169ZV2v63v/1NCQkJtgQFAEB1hFy5TZs2TSkpKSooKFAgENCyZcu0c+dOZWVl6Z133qmJGAEANjP9lTchV27Dhw/X22+/rdWrVysyMlLTpk3T559/rrfffls33nhjTcQIALCZkxMn14bzes7t+uuvV05Ojt2xAABgC+aWBAAXqs7zafVByMktLCxMHs/p/0cpLy+vVkAAgJp3PkP465OQk9vy5cuD1ktLS/XJJ59o8eLFeuyxx2wLDACA8xVycqtqepTbb79d3bp109KlS3XPPffYEhgAoOYwWvIcXXPNNcrNzbXrdACAGlQX5pasSbYktx9++EFz585V+/bt7TgdAADVEnJbsmXLlkEDSizL0vHjx9WkSRMtWbLE1uAAADWDASX/Zs6cOUHrYWFhioqKUp8+fdSyZUu74gIA1CDT77mFlNzKysq0d+9ejRs3ThdccEFNxWQbXyb3AFE7ykoPOB0CgH8R0j23iIgIPfXUUyorK6upeAAAtYABJf/ml7/8pT788MOaiAUAUEucfJ9bbQj5nltSUpKmTJmi7du3q2fPnoqMjAzaP2zYMNuCAwDgfHgsK7TbimFhpy/2PB5P3Zh+66fRnBENYh0OBKb693tspd/ucSgSmK5BVJcff7B5BMjG2NtsO1efA8tsO5ddQq7cAoFATcQBAKhFhg+WDP2eW1ZWlvx+f6Xtp06dUlZWli1BAQBQHSEnt7Fjx6qwsLDS9uPHj2vs2LG2BAUAqFmmj5YMuS1pWVaVr7zZv3+/fD6fLUEBAGpWXR3laJdzTm4JCQnyeDzyeDwaOHCgIiL++dHy8nLl5+frpptuqpEgAQAIxTkntxEjRkiS8vLyNHjwYDVt2rRiX8OGDdW5c2f96le/sj1AAID9TB8aeM7Jbfr06ZKkzp0764477lCjRo3OePzrr7+uYcOGVXoODgDgPEtmtyVDHlCSkpJy1sQmSb/97W91+PDh8woKAIDqCHlAybkK8dlwAEAtChj+J7rGkhsAoO4K0JYEAKB+oXIDABcyfUAJyQ0AXMj0RwHOa7Tk2rVrz3pcp06d1KBBg/MKCgCA6gg5uRUWFioxMVEXX3yxnnzySRUUFFR53KeffqoOHTpUO0AAgP0seWxb6qKQk1t2drYKCgr0wAMPaOnSpercubOSkpL0t7/9TaWlpTURIwDAZgEbl1CUl5dr6tSpuvDCC9W4cWN16dJFM2bMsP3xsfMaLRkVFaXU1FRt27ZNGzduVFxcnO666y7FxsZq8uTJ2rVrl61BAgDMMGvWLC1YsEDz5s3T559/rlmzZmn27Nl6/vnnbb1OtQaUHDx4UDk5OcrJyVF4eLhuvvlmbd++XZdffrlmz56tyZMn2xUnAMBGdg4o8fv9ld7z6fV65fV6Kx370Ucfafjw4RoyZIikH6d0fP3117Vp0yYbIzqPyq20tFRvvfWWbrnlFnXq1El//etfNWnSJB04cECLFy/W6tWr9eabb+qPf/yjrYECAOxj5z23jIwM+Xy+oCUjI6PK6/br10+5ubn64osvJEnbtm3T+vXrlZSUZOv3C7lyi4mJUSAQ0KhRo7Rp0yb16NGj0jEDBgxQixYtbAgPAFDXpaWlKTU1NWhbVVWbJE2ZMkVFRUXq2rWrwsPDVV5erieeeEKjR4+2NaaQk9tzzz2nkSNHnnHy5BYtWig/P79agQEAak7AxkGOp2tBVuXNN9/Ua6+9pr/85S/q1q2b8vLyNGnSJMXGxiolJcW2mDyWiTMc//Sm8IgGsQ4HAlOVlR4IWi/9do9DkcB0DaK6/PiDzX+q/7vdr2071/BDfznnYzt06KApU6Zo/PjxFdsef/xxLVmyRDt27LAtJuaWBADUmhMnTigsLDj1hIeHKxCwd84Upt8CABdyqmU3dOhQPfHEE+rYsaO6deumTz75RM8++6zGjRtn63VIbgDgQk7NLfn8889r6tSpevDBB/XNN98oNjZWv/3tbzVt2jRbr8M9N+A8cM8NtaWm7rkts/Ge220h3HOrLVRuAOBCAU/dnBPSLiQ3AHAh81p2wRgtCQAwDpUbALiQ6S8rJbkBgAvZOUNJXURbEgBgHCo3AHChQB19g7ZdSG4A4EKMlgQAoJ6hcgMAFzJ9QAnJDQBcyPRHAWhLAgCMQ+UGAC5k+oASkhsAuJDp99xoSwIAjEPlBgAuZPqAEpIbALiQ6cmNtiQAwDhUbgDgQpbhA0pIbgDgQrQlAQCoZ6jcAMCFTK/cSG4A4EKmz1BCWxIAYBwqNwBwIdOn3yK5AYALmX7PjbYkAMA4VG4A4EKmV24kNwBwIUZLAgBQz1C5AYALMVoSAGAc0++50ZYEANSazp07y+PxVFrGjx9v63Wo3ADAhZwaULJ582aVl5dXrH/66ae68cYbNXLkSFuvQ3IDABcK2Jje/H6//H5/0Dav1yuv11vp2KioqKD1mTNnqkuXLrrhhhtsi0eiLQkAqKaMjAz5fL6gJSMj46yfO3XqlJYsWaJx48bJ47F3hAuVGwC4kJ0DStLS0pSamhq0raqq7d9lZ2fr2LFjGjNmjI3R/IjkBgAuZOc9t9O1IM/m5ZdfVlJSkmJjY22M5kckNwBArdu7d69Wr16tZcuW1cj5SW4A4EJOP+f2yiuvqG3bthoyZEiNnJ/kBgAu5OQMJYFAQK+88opSUlIUEVEzaYjRkgCAWrV69Wrt27dP48aNq7FrULkBgAvZ+ZxbqAYNGiTLqtnrk9wAwIV45Q0AAPUMlRsAuJDToyVrGskNAFzIyXtutYG2JADAOFRuAOBCZtdtJDcAcCXT77nRlgQAGIfKDQBcyPQBJSQ3AHAhs1MbbUkAgIGo3ADAhUwfUEJyAwAXsgxvTNKWBAAYh8oNAFyItiQAwDimPwpAWxIAYBwqNwBwIbPrNpIbALgSbUm4xiMPj1fZqQI98/RjTocCA2zJ267xj0zXgGGj1f3aJOWu/Sho//yXl2joqPvUe+AI9btppO79fZr+97MdDkUL05DcIEnq1TNe9937G2373//ndCgwxA8/nNSlcRfpP//wYJX7O3dor/9IfVDLshYo64WnFdsuWvdP/k99f/RY7QbqUgEbl7qItiQUGdlEWVnz9LsHHtF/pE10OhwY4vq+vXV9396n3T9k0ICg9Ucm3qdl76zSF3vydU2vhJoOz/V4iBvGe37uk3rvf3KV+/46p0OBS5WWluqv//2emjWN1KVxFzkdDgxQ7ys3v98vv98ftM3704KzS04epoSE7rqm7xCnQ4ELrfn7Rj08faZOnvQrqnUrLZzzhFq28DkdlivU1XaiXep05fb1119r3LhxZzwmIyNDPp8vaMmopfjquwsuiNVzz/xRd6dMqPQPBKA2XH1VvN7KnK8lLz6ja6/pqYemZug77rnVCsvG/+qiOp3cvv/+ey1evPiMx6SlpamwsDBoSaul+Oq7q666QtHRUdq8caVOntirkyf26oYb+mnC/xmnkyf2KiysTv96wABNGjdSxwtiFd/9Ms1Im6zw8HAte3uV02HBAI62JVesWHHG/V9++eVZz+H1euX10oQ8H++/v17xCb8M2vanRc9q5849eurp+QoETG9coK4JBAI6VVrqdBiuYPr/ux1NbiNGjJDH45Flnb6s9Xg8tRiRuxQXl+izz3YGbTtRckLffXe00nYgVCdO/KB9+w9UrBccOKwdX+yRr3kz+XzNtXDxGxpwXR9FtWmlo8eK9Pqyt/XNke80eMD1DkbtHoEz/N01gaPJLSYmRi+88IKGDx9e5f68vDz17NmzlqMCYIdPd+zSuAmPVqzPfn6hJGl4UqKmPTxB+Xu/1or3VutoYaFaNG+u7pddosUvPKW4izo5FTIM4mhy69mzpz7++OPTJrezVXWw38AbRzodAgxx9VVX6tO/v3fa/f83Y2otRoN/Z/pfVkeT28MPP6ySkpLT7o+Li9MHH3xQixEBgDswt2QNuv7663XTTTeddn9kZKRuuOGGWowIAFDTCgoK9Jvf/EatW7dW48aNdcUVV2jLli22XqPeP8QNAAidU8+nHT16VNdee60GDBig9957T1FRUdq1a5datmxp63VIbgDgQk49CjBr1ix16NBBr7zySsW2Cy+80Pbr8JQuAKBa/H6/ioqKgpbTzXq0YsUK9erVSyNHjlTbtm2VkJCgRYsW2R4TyQ0AXCggy7alymkQM6qeCPHLL7/UggULdPHFF2vVqlV64IEHNHHixLPORhUqj2XiWPufHvyOaBDrcCAwVVnpgaD10m/3OBQJTNcgqsuPP9j8p/r2TsNsO9drX/y18gT2p5k9qmHDhurVq5c++uifL6+dOHGiNm/erA0bNtgWE/fcAADVEso0iDExMbr88suDtl122WV66623bI2J5AYALuTUgJJrr71WO3cGT+/3xRdfqFMne2emIbkBgAs5dUdq8uTJ6tevn5588kklJydr06ZNWrhwoRYuXGjrdRhQAgCoNb1799by5cv1+uuvq3v37poxY4bmzJmj0aNH23odKjcAcCEnp9+65ZZbdMstt9ToNUhuAOBCpr/PjbYkAMA4VG4A4EJOzS1ZW0huAOBCvPIGAIB6hsoNAFzIxJkX/xXJDQBciNGSAADUM1RuAOBCjJYEABiH0ZIAANQzVG4A4EKMlgQAGIe2JAAA9QyVGwC4EKMlAQDGCRh+z422JADAOFRuAOBCZtdtJDcAcCVGSwIAUM9QuQGAC5leuZHcAMCFTJ+hhLYkAMA4VG4A4EK0JQEAxjF9hhLakgAA41C5AYALmT6ghOQGAC5k+j032pIAAONQuQGAC9GWBAAYh7YkAAD1DMkNAFzIsvG/UKSnp8vj8QQtXbt2tf370ZYEABdy8k3c3bp10+rVqyvWIyLsT0UkNwBArYqIiFC7du1q9Bq0JQHAhexsS/r9fhUVFQUtfr//tNfetWuXYmNjddFFF2n06NHat2+f7d+P5AYALhSwLNuWjIwM+Xy+oCUjI6PK6/bp00eZmZlauXKlFixYoPz8fF1//fU6fvy4rd/PY5n4sIPHI0mKaBDrcCAwVVnpgaD10m/3OBQJTNcgqsuPP9j8p/qytlfbdq68r9dVqtS8Xq+8Xu9ZP3vs2DF16tRJzz77rO655x7bYuKeGwC4kJ1vBTjXRFaVFi1a6JJLLtHu3btti0eiLQkArmRnW7I6iouLtWfPHsXExNj0zX5EcgMA1JqHHnpIH374ob766it99NFHuvXWWxUeHq5Ro0bZeh3akgDgQk69rHT//v0aNWqUvvvuO0VFRem6667TP/7xD0VFRdl6HZIbALiQUw9xv/HGG7VyHdqSAADjULkBgAs51ZasLSQ3AHAhywo4HUKNoi0JADAOlRsAuBAvKwUAoJ6hcgMAFzJxWuF/RXIDABeiLQkAQD1D5QYALkRbEgBgHKem36ottCUBAMahcgMAF2L6LQCAcUy/50ZbEgBgHCo3AHAh059zI7kBgAvRlgQAoJ6hcgMAFzL9OTeSGwC4EG1JAADqGSo3AHAhRksCAIxDWxIAgHqGyg0AXIjRkgAA45g+cTJtSQCAcajcAMCFaEsCAIzDaEkAAOoZKjcAcCHTB5SQ3ADAhWhLAgBQA2bOnCmPx6NJkybZfm4qNwBwIacrt82bN+ull17SlVdeWSPnNzq5lZUecDoEuESDqC5OhwCExMnUVlxcrNGjR2vRokV6/PHHa+QatCUBANXi9/tVVFQUtPj9/tMeP378eA0ZMkSJiYk1FpOZlZvhN0prgt/vV0ZGhtLS0uT1ep0OBwbjd61uKDtVYNu50tPT9dhjjwVtmz59utLT0ysd+8Ybb2jr1q3avHmzbdevisdyuvGKOqGoqEg+n0+FhYVq3ry50+HAYPyumcfv91eq1Lxeb6V/vHz99dfq1auXcnJyKu619e/fXz169NCcOXNsjYnkBkn8wUHt4XfNvbKzs3XrrbcqPDy8Ylt5ebk8Ho/CwsLk9/uD9lWHmW1JAECdM3DgQG3fvj1o29ixY9W1a1c9+uijtiU2ieQGAKglzZo1U/fu3YO2RUZGqnXr1pW2VxejJSHpx/749OnTucGPGsfvGmoD99wAAMahcgMAGIfkBgAwDskNAGAckhsAwDgkN2j+/Pnq3LmzGjVqpD59+mjTpk1OhwQDrV27VkOHDlVsbKw8Ho+ys7OdDgkGI7m53NKlS5Wamqrp06dr69atio+P1+DBg/XNN984HRoMU1JSovj4eM2fP9/pUOACPArgcn369FHv3r01b948SVIgEFCHDh00YcIETZkyxeHoYCqPx6Ply5drxIgRTocCQ1G5udipU6f08ccfB712IiwsTImJidqwYYODkQFA9ZDcXOzIkSMqLy9XdHR00Pbo6GgdOnTIoagAoPpIbgAA45DcXKxNmzYKDw/X4cOHg7YfPnxY7dq1cygqAKg+kpuLNWzYUD179lRubm7FtkAgoNzcXPXt29fByACgenjljculpqYqJSVFvXr10tVXX605c+aopKREY8eOdTo0GKa4uFi7d++uWM/Pz1deXp5atWqljh07OhgZTMSjANC8efP01FNP6dChQ+rRo4fmzp2rPn36OB0WDLNmzRoNGDCg0vaUlBRlZmbWfkAwGskNAGAc7rkBAIxDcgMAGIfkBgAwDskNAGAckhsAwDgkNwCAcUhuAADjkNwAAMYhuQF1yJgxY3iBJ2ADkhsAwDgkN8Bmp06dcjoEwPVIbjBeVlaWWrduLb/fH7R9xIgRuuuuu8742fT0dPXo0UMvvfSSOnTooCZNmig5OVmFhYUVx/zcSnziiScUGxurSy+9VJL09ddfKzk5WS1atFCrVq00fPhwffXVVxWfKy8vV2pqqlq0aKHWrVvrkUceEVO9AvYgucF4I0eOVHl5uVasWFGx7ZtvvtG7776rcePGnfXzu3fv1ptvvqm3335bK1eu1CeffKIHH3ww6Jjc3Fzt3LlTOTk5euedd1RaWqrBgwerWbNmWrdunf7+97+radOmuummmyoqu2eeeUaZmZn685//rPXr1+v777/X8uXL7f3ygFtZgAs88MADVlJSUsX6M888Y1100UVWIBA44+emT59uhYeHW/v376/Y9t5771lhYWHWwYMHLcuyrJSUFCs6Otry+/0Vx7z66qvWpZdeGnR+v99vNW7c2Fq1apVlWZYVExNjzZ49u2J/aWmpdcEFF1jDhw+v1ncFYFm8rBSucN9996l3794qKChQ+/btlZmZqTFjxsjj8Zz1sx07dlT79u0r1vv27atAIKCdO3eqXbt2kqQrrrhCDRs2rDhm27Zt2r17t5o1axZ0rpMnT2rPnj0qLCzUwYMHg96bFxERoV69etGaBGxAcoMrJCQkKD4+XllZWRo0aJA+++wzvfvuu7adPzIyMmi9uLhYPXv21GuvvVbp2KioKNuuC6BqJDe4xr333qs5c+aooKBAiYmJ6tChwzl9bt++fTpw4IBiY2MlSf/4xz8UFhZWMXCkKldddZWWLl2qtm3bqnnz5lUeExMTo40bN+oXv/iFJKmsrEwff/yxrrrqqhC/GYB/x4ASuMavf/1r7d+/X4sWLTqngSQ/a9SokVJSUrRt2zatW7dOEydOVHJyckVLsiqjR49WmzZtNHz4cK1bt075+flas2aNJk6cqP3790uSfv/732vmzJnKzs7Wjh079OCDD+rYsWPV/ZoARHKDi/h8Pv3qV79S06ZNQ5oFJC4uTrfddptuvvlmDRo0SFdeeaVeeOGFM36mSZMmWrt2rTp27KjbbrtNl112me655x6dPHmyopL7wx/+oLvuukspKSnq27evmjVrpltvvbU6XxHATzwWd6/hIgMHDlS3bt00d+7cczo+PT1d2dnZysvLq9nAANiKe25whaNHj2rNmjVas2bNWasuAPUfyQ2ukJCQoKNHj2rWrFlBA0G6deumvXv3VvmZl156qbbCA2Az2pJwtb1796q0tLTKfdHR0ZWeUwNQP5DcAADGYbQkAMA4JDcAgHFIbgAA45DcAADGIbkBAIxDcgMAGIfkBgAwzv8HLFdJu+SrdwAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.71      0.71        14\n",
            "           1       0.76      0.76      0.76        17\n",
            "\n",
            "    accuracy                           0.74        31\n",
            "   macro avg       0.74      0.74      0.74        31\n",
            "weighted avg       0.74      0.74      0.74        31\n",
            "\n"
          ]
        }
      ]
    }
  ]
}